\chapter{Extending a Brainiac Prover to Higher-Order Logic}
\setheader{Extending a Brainiac Prover to Higher-Order Logic}
\label{ch:ehoh2}

% \renewcommand{chapter}[0]{chapter}
\newcommand\ehohii{$\lambda$E}


\blfootnote{In this work I designed, implemented and evaluated all changes to
term representation, algorithms and indexing data structures. Jasmin Blanchette
did the daily supervision. Stephan Schulz provided
the necessary E expertise.}

\begin{abstract}%
    The automatic discharge of tedious subgoals is high on the wishlist of many
  users of proof assistants. Some proof assistants discharge such goals
  by translating them to first-order logic and invoking an efficient prover on
  them, but much is lost in translation. As an alternative,
  we propose to extend first-order provers with native support for
  higher-order features. Building on our extension of E to $\lambda$-free
  higher-order logic, we now extend E to full higher-order logic.
  The resulting prover is the \NumberOK{strongest} one on benchmarks coming from a
  proof assistant, and the second best on TPTP benchmarks.
    %It also incurs no overhead on first-order problems.  -- sounds like a detail --JB
\end{abstract}

\newpage

\section{Introduction and Background}
\label{sec:ehoh2:introduction}

In Chapter~\ref{ch:ehoh} of this thesis we introduced Ehoh, a rather conservative extension of
state-of-the-art first-order prover to a fragment of higher-order logic devoid of $\lambda$-abstraction. This
extension gave us a flavor of the difficulties that we might encounter on the
way to full higher-order logic. In chapters that precede this one,
we discussed many ways in which those difficulties can be overcome.
In this chapter, we fulfill a promise we gave in the beginning of the thesis: We present the extension of
Ehoh to full higher-order logic using incomplete variants
of $\lambda$-superposition. We call this prover \ehohii.

%
The $\lambda$-superposition calculi were
previously implemented in Zipperposition, and
extensive experiments with various heuristic choices have been performed
(Chapter \ref{ch:ho-techniques}). In \ehohii{}'s implementation, we used
these experiences to choose a set of effective rules that could easily be
retrofitted into an originally first-order prover. Another principle that guided 
the design of \ehohii{} was \emph{gracefulness}: we made sure that our changes
do not impact the strong first-order performance of E and $\lambda$-free higher-order performance of Ehoh. 

% We
% also used the experience of fine-tuning the calculi
% \cite{section-making-ho-work} in Zipperposition to carefully choose which
% calculus extensions and heuristics to use in E.

One of the main challenges we faced was retrofitting $\lambda$-terms in Ehoh's
term representation (Sect.~\ref{sec:ehoh2:terms}). Furthermore, Ehoh's main inference
engine was designed with the assumption that it will be used with
inferences that compute a most general unifier. We
implemented a higher-order unification procedure (Chapter \ref{ch:unif})
that can return multiple unifiers (Sect.~\ref{sec:ehoh2:unif-match-index}) and
integrated it in the inference engine. Finally, we extended and adapted the
superposition rule, resulting in an incomplete, pragmatic variant of
$\lambda$-superposition (Sect.~\ref{sec:ehoh2:calculus}).

We \NumberOK{evaluated} \ehohii{} on a selection of proof assistants benchmarks
as well as all higher-order theorems in the TPTP library \cite{gs-17-tptp}
(Sect.~\ref{sec:ehoh2:eval}). We found
that \ehohii{} clearly outperforms Ehoh on all benchmarks. It outperformed all other higher-order provers on
proof assistant benchmarks; on TPTP benchmarks it ended up second only 
to the cooperative version of Zipperposition, which employs Ehoh as a
backend. An arguably fairer comparison without the backend puts \ehohii{} in the
first place for both benchmark suites.
We also compared the performance of \ehohii{} with E on first-order
%%% @PETAR: I made this slightly sentence shorter and more forceful. Please
%%% check if you agree. --JB
problems and found that little overhead has been introduced by the
extension to higher-order logic.

\ourpara{Background} The logic \ehohii{} targets is the monomorphic higher-order
logic described in Sect.~\ref{sec:pre:hol}. We reuse all the notions from this
section, with the corresponding notations. Like in the previous chapter, we
simplify the notation by writing predicate literals in unencoded form: Positive
literal $\eqlit{s}{\itrue}$ is written as $s$ and negative literal
$\neqlit{s}{\top}$ is written as $\negpredlit{s}$.   This chapter discusses
three tightly related provers E, Ehoh and \ehohii{}, which are disambiguated as
follows:

\begin{itemize}
  \item E is a state-of-the-art first-order prover based on superposition. It is described in
  Sect.~\ref{sec:pre:theorem-provers}.
  \item Ehoh is an extension of E to support $\lambda$-free higher-order logic. Chapter \ref{ch:ehoh}
  is dedicated to Ehoh.
  \item \ehohii{} further builds on Ehoh to support full higher-order logic. It is the latest prover
  described in this chapter.
\end{itemize}

\section{Terms}
\label{sec:ehoh2:terms}

\looseness=-1
E has been designed around perfect term sharing %or exa
\cite{ls-01-shared}, a design that we carried on to  Ehoh and \ehohii{}: Any two structurally identical terms are
guaranteed to be the same object in memory. This is achieved through term
\emph{cells}, which represent individual terms. Each cell has (among other fields)
(1)~\texttt{f\_code}, an integer corresponding to the symbol at the head of the term (negative
if the head is a free variable, positive otherwise); (2)~\texttt{num\_args},
corresponding to the number of arguments applied to the head; and (3)~\texttt{args},
a size-\texttt{num\_args} array of pointers to argument terms. We
use the first-order notation $\cst{f}(s_1, \ldots, s_n)$ to denote a cell whose
\texttt{f\_code} corresponds to $\cst{f}$, \texttt{num\_args} equals $n$, and
\texttt{args} points to the cells for $s_1, \ldots s_n$.

Ehoh represents $\lambda$-free higher-order terms using flattened, spine notation
(Sect.~\ref{sec:ehoh:types-and-terms}).
Thus, the terms $\cst{f}$, $\cst{f} \, \cst{a}$ and $\cst{f} \, \cst{a} \,
\cst{b}$ are represented by the cells $\cst{f}$,
$\cst{f}(\cst{a})$, and $\cst{f}(\cst{a}, \cst{b})$, respectively.
To ensure free variables are
perfectly shared, Ehoh treats applied free variables differently: arguments are
not applied directly to a free variable, but using an internal symbol
\internalat{} of variable arity. For example, the term $X \, \cst{a} \, \cst{b}$ is
represented by the cell $\internalat(X, \cst{a}, \cst{b})$. This ensures that
two different occurrences of the free variable $X$ correspond to the same object,
which makes substitutions more efficient.
%%% @PETAR(read): This tries to explain an invisible problem. Either we need to explain
%%% it better, or we just omit it (my favorite option). It's old Ehoh stuff anyway. --JB
%Yet, to
%efficiently access variable arguments we do not use binary application symbol,
%but flattened representation.

\ourpara{Representation of $\lambdabf$-Terms} To support full
higher-order logic, Ehoh's $\lambda$-free cell data structure must
be extended to support the $\lambda$ binder. We use the locally nameless
representation \cite{ac-12-locally-nameless} for this purpose: De Bruijn indices
%%% @PETAR(checked): Double-check "possibly loose".
represent (possibly loose) bound variables, whereas we keep the current
representation for free (and applied) variables.

%%% @PETAR(read): Sounds odd---we wouldn't be extending the term representation of an
%%% already HO prover. --JB
%Unlike other higher-order provers, most of which are written in functional
%programming languages,
Extending the term representation of Ehoh with a new term
kind involves intricate manipulation of the cell data structure. De Bruijn
indices must be represented as other cells with either negative or positive
\texttt{f\_code}. However, this has to be done in such a way that De Bruijn
index can never be mistaken for a function symbol or a variable.

Other than possibly being instantiated during $\beta$-reduction, De Bruijn
indices mostly behave as constants. Therefore, we decided to represent De
Bruijn indices using positive \texttt{f\_code}s: The De Bruijn index of value $i$
will have $i$ as the~\verb|f_code|. To ensure De Bruijn indices are not
mistaken for function symbols, we use the \texttt{properties} bitfield of the
cell, which holds precomputed properties of %shared cell
%%% @PETAR(checked, you are right): I don't understand why you wrote "shared cell". Please double-check. --JB
the cell. We introduce the
property \texttt{IsDBVar} to denote that the cell represents a De
Bruijn index. Any attempt to create a De Bruijn index is performed through
a dedicated library function that sets \texttt{IsDBVar} property for every term it
returns. When given the same De Bruijn index and type, this function is
guaranteed to always return the same object. Finally, we have guarded all the
functions and macros that manipulate function codes with the check if the
property \texttt{IsDBVar} is set. To ensure perfect sharing of every occurrence
of De Bruijn indices, arguments to De Bruijn indices are applied like for free
variables, using \internalat{}.

Extending cells to support $\lambda$-abstraction is easier. Each
$\lambda$-ab\-strac\-tion has the distinguished function code \internallam{} as the head
symbol and two arguments:\ (1)~a De Bruijn index 0 of the type of abstracted variable;
(2)~the body %(matrix)
of the $\lambda$-abstraction. Consider
the term $\lambda x. \, \lambda y.\, \cst{f}\, x \, x$, where both $x$ and $y$ have
the type~$\iota$. This term is represented as $\lambda\,\lambda\, \cst{f} \,
\db{1} \, \db{1}$ in locally nameless representation, where bold numbers
represent De Bruijn indices. In \ehohii{}, the same term is represented by the cell
$\internallam(\db{0}, \internallam(\db{0}, \cst{f}(\db{1}, \db{1})))$,
where all De Bruijn variables have type~$\iota$. 

The first argument of $\internallam$ is
redundant, since it can be deduced from the type of the $\lambda$-abstraction.
However, basic $\lambda$-term manipulation operations often require access to
this term. We store it explicitly to avoid creating it repeatedly.

\ourpara{Efficient $\betabf$-Reduction}
Terms are stored in $\beta\eta$-reduced form. As these two reductions are
performed very often, they ought to be efficient. \ehohii{}
performs $\beta$-reduction by reducing the leftmost outermost $\beta$-redex
first. To represent $\beta$-redexes, it uses the \internalat{} symbol. Thus,
the term $(\lambda
x.\, \lambda y.\,  (x \, y)) \, \cst{f} \, \cst{a}$ is represented by
$\internalat(\internallam(\db{0}, \internallam(\db{0}, \internalat(\db{1}, \db{0}))),
\cst{f}, \cst{a})$. Another option would have been to add arguments applied to
$\lambda$-term directly to the $\lambda$ representation (as in
$\internallam(\db{0}, \internallam(\db{0}, \allowbreak \internalat(\db{1}, \db{0})),
\cst{f}, \cst{a})$), but this would break the invariant
that $\internallam$ has two arguments. Furthermore, replacing free
variables with $\lambda$-abstractions (e.g., replacing $X$ with $\lambda
x. \, x$ in $\internalat(X, \cst{a})$) would require additional normalization.

A term can be $\beta$-reduced as follows: When a cell of the
form $ \internalat(\internallam(\db{0}, s),t)$ is encountered, the field
\texttt{binding} (normally used to record the substitution for a free variable) of the
cell $\db{0}$ is set to $t$. Then $s$ is traversed to instantiate every
loose occurrence of $\db{0}$ in $s$ with \texttt{binding}, whose loosely
bound De Bruijn indices are shifted by the number of $\lambda$ binders above
the occurrence of $\db{0}$ in $s$ \cite{fk-01-deBruijn}. Next, the same
procedure is performed on the resulting term and its subterms, in
leftmost outermost fashion.

\ehohii{}'s basic $\beta$-normalization mechanism works in this way, but it
features a few optimizations.
First, \ehohii{} recognizes terms of the form $(\lam{\overline{x}_n}{s}) \,\overline{t}_n$ 
and performs parallel replacement of the bound variables $x_i$ with
$t_i$. Since intermediate terms are not constructed, this reduces the number of
recursive function calls and calls to the cell allocator.

Second, in line with the gracefulness principle, we want \ehohii{} to incur
little (if any) overhead on first-order problems and to
excel on higher-order problems with a large first-order component. If
$\beta$-reduction is implemented naively, finding a $\beta$-redex involves
traversing the entire term. On purely first-order terms, $\beta$-reduction
is then a complete waste of time.

To avoid this, we use Ehoh's perfectly shared
terms and their \texttt{properties} field.
%
We introduce the property \texttt{HasBetaReducibleSubterm} which is set if
%%% @PETAR(is is good): "is" or "may be" below? (Overapproximation?) --JB
a cell is $\beta$-reducible.
Whenever a new cell that contains a
$\beta$-reducible term as a direct subterm is shared, the property is set.
Setting of the property is inductively continued when further superterms are
shared. For example, in the term $t = \cst{f} \, \cst{a} \, (\cst{g} ((\lambda x.\,
x)\,\cst{a}))$, the cells for $(\lambda x.\, x)\,\cst{a}$,
$\cst{g}\,((\lambda x.\, x)\,\cst{a})$, and $t$ itself have the property
\texttt{HasBetaReducibleSubterm} set.
%
When it needs to find $\beta$-reducible subterms, \ehohii{} will visit only the
cells with this property set. This further means that on first-order
subterms, a single bit masking operation is enough to determine that no subterm
should be visited.

Along similar lines, we added a property \texttt{HasDBSubterm} that
caches whether the cell contains a De Bruijn subterm. This
%% @PETAR(you are right): Why "also"? What's the other thing?
%also
makes
instantiating De Bruijn indices during $\beta$-norma\-lization faster, since only the
subterms that contain De Bruijn indices must be visited. Similarly, some other
operations such as shifting De Bruijn indices or determining whether a term is closed
(i.e., it contains no loose bound variables) can be sped up or even avoided
if the term is first-order.

\ourpara{Efficient $\etabf$-Reduction}
The term $\lambda x.\, s \, x$ is $\eta$-reduced to $s$ whenever $x$ does not appear
unbound in $s$. Caching the property of $\eta$-reducibility of the term is not
as beneficial as the one for $\beta$-reducibility, because checking this
property at the term's top level is done in $O(|s|)$, compared with constant time
for $\beta$-reducibility.
However, we use the observation that a term cannot be $\eta$-reduced if it has
no $\lambda$-abstraction subterms and introduce a property \texttt{HasLambda}
that notes the presence of $\lambda$-abstraction in a term. Only
terms with this property are visited during $\eta$-reduction.

\ehohii{} performs parallel $\eta$-reduction: It recognizes terms of the form
$\lam{\overline{x}_n}{s \, \overline{x}_n } $ such that none of $x_i$
occurs unbound in $s$. If done naively, reducing terms of this kind requires up to $n$
traversals of $s$ to check if each $x_i$ occurs in $s$. In \ehohii{}, exactly one
traversal of $s$ is required.

\looseness=-1
More specifically, when $\eta$-reducing a cell $\internallam(\db{0}, s)$,
\ehohii{} considers all $\lambda$ binders in $s$ as well. In general,
the cell will be of the form
$\internallam(\db{0}, \dotsc,\allowbreak \internallam(\db{0}, t) \ldots)$,
where $t$ is not a
$\lambda$-abstraction, and $l$ is the number of $\internallam$ symbols above $t$. Then \ehohii{} breaks down the body~$t$ into a maximal
decomposition $u\, (\dbvar{n}\db{{}-1}) \, \ldots \, \db{1} \, \db{0}$.
If $n = 0$, the cell is not $\eta$-reducible.
Otherwise, $u$ is traversed to determine the
minimal index~$\dbvar{j}$ of a loose De Bruijn index,
taking $\dbvar{j} = \infty$ if no such index exists.
%%% @PETAR(I prefer leftmost as we are going top level left-to-right and not
%bottom-up as innermost can suggest): Check "innermost".
%%% @PETAR(you are right, but I will add righmost outermost to be more precise): But it's rightmost then not leftmost! In the example, the very first
%%% binder remains (the one to which the 2's point). --JB
We can then remove the $k = \min\{j,l,n\}$ rightmost outermost $\lambda$ binders in $\internallam(\db{0},
\ldots, \internallam(\db{0}, t) \ldots)$ and replace %the body
$t$ by the variant of
$u \allowbreak\, (\dbvar{n}\db{{}-1}) \allowbreak\, \ldots \, (\dbvar{k}\db{{}+1}) \, \dbvar{k}$
obtained by shifting the loose De Bruijn indices right by~$k$.

To better understand this convoluted De Bruijn arithmetic, consider the
term $\lambda x. \, \lambda y. \, \lambda z.\,\allowbreak \cst{f} \, x \, x \, y
\, z$. This term is represented by the cell $\internallam(\db{0},
\internallam(\db{0}, \internallam(\db{0},\allowbreak \cst{f}(\db{2}, \db{2}, \db{1},
\db{0}))))$. \ehohii{} splits $\cst{f}(\db{2}, \db{2}, \db{1}, \db{0})$ into
two parts:\ $u = \cst{f} \, \db{2}$ and the arguments $\db{2}, \db{1},
\db{0}$. Since the minimal index in $u$ is $\db{2}$, we can
omit the De Bruijn indices $\db{1}$ and $\db{0}$ and their $\lambda$ binders,
yielding the $\eta$-reduced cell $\internallam(\db{0}, \cst{f}(\db{0},
\db{0}))$.

The use of the \texttt{HasLambda} property ensures that $\eta$-reduction is not
tried on first-order or $\lambda$-free higher-order terms, whereas parallel
$\eta$-reduction both speeds up $\eta$-reduction and avoids creating a linear
number of intermediate terms. For finding the minimal loose De Bruijn index,
optimizations such as the \texttt{HasDBSub\-term} property are used.

\ourpara{Representation of Boolean Terms}
Ehoh represents Boolean terms using
cells whose \texttt{f\_code}s correspond to internal codes reserved
for logical symbols. Quantified formulas are represented by cells in which the
first argument is the quantified variable and the second one is the body of the
quantified formula. For example, the term $\iforall x.\, \cst{p} \, x$ corresponds
to the cell $\iforall(X, \cst{p}(X))$, where $X$ is a regular free variable.
% as Ehoh has no concept of a bound variable.

This representation is convenient for parsing formulas and clausification, which
is what Ehoh uses it for, but it
causes $\alpha$-normalization issues during the actual proof search: In
full higher-order logic, Boolean terms can appear as subterms in clauses, as in
$\cst{q}(X) \llor \cst{p}(\iforall(X, \cst{r}(X)))$;
instantiating $X$ in the first literal should not influence $X$ in the second
literal.

To avoid this issue, in \ehohii{} we use $\lambda$ binders to represent quantified formulas.
Thus, $\iforall x. \, s$ is represented by $\iforall \, (\lambda x. \, s)$.
Quantifiers are then unary symbols that do not directly bind
the variables but delegate this responsibility to a $\lambda$-abstraction.
%
Since \ehohii{} represents bound variables using De Bruijn indices, this solves the
$\alpha$-conversion issues. However, this solution is incompatible with
thousands of decades-old lines of clausification code that assumes the Ehoh
representation of
quantified formulas. Therefore, \ehohii{} converts quantified
formulas only after clausification, for Boolean terms that appear in a
higher-order context (e.g., as argument to a function symbol).

\ourpara{New Term Orders}
The $\lambda$-superposition calculus is parameterized by a term order that is
used to break symmetries in the search space.
We implemented the versions of the Knuth--Bendix order (KBO) and lexicographic
path order (LPO) for higher-order terms with $\lambda$-abstractions described by
Bentkamp et al.~\cite{bbtv-21-full-ho-sup}. These orders encode
encode $\lambda$-terms as first-order terms and then invoke the standard KBO or
LPO. %Trading elegance for efficiency, our
%implementation does not compute the first-order translation.
%Rather,
For efficiency, we implemented separate KBO and
LPO functions that compute the order directly, intertwining the encoding and
the order computation.
%%% @PETAR(yes): Irrelevant detail?
%We kept the
%implementation of $\lambda$-free KBO as \ehohii{} can be run in $\lambda$-free mode.

Ehoh cells contain a \verb|binding| field that can be used to store the
substitution for a free variable. Substitutions can then be applied by following
the \texttt{binding} pointers, replacing each free variable with its instance.
Thus, when Ehoh needs to perform a KBO or LPO comparison of an instantiated term,
it needs only follow the \texttt{binding} pointers.
In full higher-order logic, however, instantiating a variable can trigger a
series of $\beta\eta$-reductions,
changing the shape of the term dramatically. To pevent this, \ehohii{}
computes the $\beta\eta$-reduced instance of the terms
before comparing them using KBO or LPO.

\section{Unification, Matching, and Term Indexing}
\label{sec:ehoh2:unif-match-index}


Standard superposition crucially depends on the concept of a most general
unifier (MGU). In higher-order logic, such a unifier does not in general exist,
and the concept
%%% @PETAR: CSU, infinite
is replaced by that of a complete set of unifiers (CSU), which may be infinite.
In Chapter \ref{ch:unif}, we described an efficient procedure to enumerate a CSU
for a term pair. It is implemented in Zipperposition, together with some
extensions to term indexing. In \ehohii{}, we further improve the performance of
this procedure by implementing a terminating, incomplete variant. We also
introduce a new indexing data structure.

\subsection{The Unification Procedure} 
% Two main guiding principles behind our
% unification procedure are laziness and redundancy elimination. The first one is
% embodied in the fact that the procedure makes sure that it never fully
% normalizes the terms or fully applies the substitution if that is not necessary.
% Redundancy elimination is achieved through \emph{oracles}
% \cite{unif-section}: the procedures that solve the unification
% problem for a subclass of higher-order terms on which unification is decidable,
% and for \ehohii{}, unary. If those procedures determine that the given terms
% belong to their class of terms, they will return the most general unifier,
% avoiding redundant computations and in some cases even non-termination.
The unification procedure works by maintaining a list of unification pairs to be solved.
After choosing a pair, it first normalizes it by $\beta$-reducing and
instantiating the heads of both terms in the pair. Then, if either head is a
variable, it computes an appropriate binding for this variable, thereby
approximating the solution.

Unlike in first-order and $\lambda$-free higher-order unification, in full
higher-order case there may be many bindings that lead to a solution. To reduce
this mostly blind guessing of bindings, the procedure features support for
\emph{oracles} (Sect.~\ref{sec:unif:the-unification-procedure}). These are
procedures that solve the unification problem for a subclass of higher-order
terms on which unification is decidable and, in the case of \ehohii{}, unary. Oracles help
increase performance, avoid nontermination, and avoid redundant bindings.

\looseness=-1
In Chapter \ref{ch:unif}, the unification procedure is described as a transition system. In
\ehohii{}, the procedure is implemented nonrecursively, and the unifiers are
enumerated using an iterator object that encapsulates the unifier
search state. The iterator consists of five fields:
\begin{enumerate}
  \item \vn{constraints}, which holds the unification
  constraints
  \item \vn{bt\_state}, a stack that contains information necessary to backtrack
  to a previous state
  \item \vn{branch\_iter}, which stores how far we
  are in exploring different possibilities from the current search node
  \item \vn{steps}, which remembers how many different unification bindings (such as
  imitation, projection, and identification) are applied
  \item \vn{subst},
  a stack storing the variables bound so far
\end{enumerate}
\pagebreak[2]
\newcommand{\cn}[1]{\ensuremath{\textsc{#1}}} %const name
\newcommand{\fc}[1]{\ensuremath{\textsc{#1}}} %function call
\algrenewcommand\alglinenumber[1]{{\color{gray} \tiny #1}}

The iterator is initialized to hold the original problem in \vn{constraints},
and all other fields are initially empty. The unifiers are retrieved one by one by
calling the function \fc{ForwardIter}. It returns \fc{True} if the iterator made
progress, in which case the unifier can be read via the iterator's
$\vn{subst}$ field. Otherwise, no more unifiers can be found, and the iterator is
no longer valid. The function's pseudocode is given below, including two
auxiliary functions \fc{NormalizeHead} and \fc{BacktrackIter}:

\vspace{\jot}
\begin{algorithmic}[]
  \Function{ForwardIter}{$\vn{iter}$}
  \State $\vn{forward} \gets \neg \vn{iter.constraints.empty()} \lor \fc{BacktrackIter}(\vn{iter})$
  \While{$\vn{forward} \land \neg \vn{iter.constraints.empty()}$}
    \State $(\vn{lhs}, \vn{rhs}) \gets $ pop pair from $\vn{iter.constraints}$
    \State $\vn{lhs} \gets \fc{NormalizeHead}(\vn{lhs})$
    \State $\vn{rhs} \gets \fc{NormalizeHead}(\vn{rhs})$
    \State normalize and discard the $\lambda$ prefix of $\vn{lhs}$ and $\vn{rhs}$

    \If{$\neg\vn{lhs.head.is\_var()} \land \vn{rhs.head.is\_var()}$}
      \State swap $\vn{lhs}$ and $\vn{rhs}$
    \EndIf

    \If{$\vn{lhs.head.is\_var()}$}
      \State $\vn{oracle\_res} \gets \fc{Fixpoint}(\vn{lhs, rhs, iter.subst}) $
      \If{$\vn{oracle\_res} = \cn{NotInFragment}$}
        \State $\vn{oracle\_res} \gets \fc{Pattern}(\vn{lhs, rhs, iter.subst}) $
      \EndIf

      \If{$\vn{oracle\_res} = \cn{NotUnifiable}$}
        \State $\vn{forward} \gets \fc{BacktrackIter(iter)}$
      \ElsIf{$\vn{oracle\_res} = \cn{NotInFragment}$}
        \State $\vn{n\_steps}, \vn{n\_branch\_iter}, \vn{n\_binding} \gets$
        \State $\quad \fc{NextBinding}(\vn{lhs}, \vn{rhs}, \vn{iter.steps}, \vn{iter.branch\_iter})$
        
        \If{$\vn{n\_branch\_iter} \not= \fc{BindEnd}$ }
          \State push pair $(\vn{lhs},\vn{rhs})$ back to \vn{iter.constraints}
          \State push quadruple $(\vn{iter.constraints}, \vn{n\_branch\_iter}, $
          \State                  $\quad \vn{iter.steps}, \vn{iter.subst})$ onto $\vn{iter.bt\_state}$
          \State extend $\vn{iter.subst}$ with $\vn{n\_binding}$
          \State $\vn{iter.steps} \gets \vn{n\_steps}$
          \State $\vn{iter.branch\_iter} \gets \cn{BindBegin}$
        \ElsIf{\vn{lhs.head = rhs.head}}
          \State create constraint pairs of arguments of $\vn{lhs}$ and $\vn{rhs}$
          \State $\quad$ and push them to \vn{iter.constrants}
          \State $\vn{iter.branch\_iter} \gets \cn{BindBegin}$
        \EndIf
      \EndIf
    \ElsIf{$\vn{lhs.head} = \vn{rhs.head}$}
      \State create constraint pairs of arguments of $\vn{lhs}$ and $\vn{rhs}$
      \State $\quad$ and push them to \vn{iter.constrants}
    \Else{} \State $\vn{forward} \gets \fc{BacktrackIter(\vn{iter})}$
    \EndIf
  \EndWhile
  \State \Return $\vn{forward}$
  \EndFunction
  
  \newpage
  
  \Function{NormalizeHead}{$\vn{t}$}
    \If{$\vn{t.head} = \internalat \land \vn{t.args}[0].\vn{is\_lambda}()$}
      \State reduce the top-level $\beta$-redex in $t$
      \State \Return $\fc{NormalizeHead}(t)$
    \ElsIf{$\vn{t.head.is\_var()} \land \vn{t.head.binding} \not= \cn{nil}$}
      \State $\vn{t.head} \gets \vn{t.head.binding}$
      \State \Return $\fc{NormalizeHead}(t)$
    \Else{}
      \State \Return $t$
    \EndIf
  \EndFunction
  
  \vspace{\jot}
  \Function{BacktrackIter}{$\vn{iter}$}
    \If{\vn{iter.bt\_state.empty()}}
      \State clear all fields in \vn{iter}
      \State \Return \cn{False}
    \Else
    \State pop $(\vn{constraints}, \vn{branch\_iter}, \vn{steps}, \vn{subst})$ from $\vn{iter.bt\_state}$
    \State set the corresponding fields of $\vn{iter}$
    \State \Return \cn{True}
    \EndIf
  \EndFunction
  \vspace{\jot}
  
\end{algorithmic} 

\looseness=-1
\fc{ForwardIter} begins by backtracking if the previous attempt was successful (i.e., 
all constraints were solved). If it finds a state from which it can continue,
it takes term pairs from $\vn{constraints}$ until
there are no more constraints or it is determined that no unifier exists. The terms
are normalized by instantiating the head variable with its binding and then
reducing the potential top-level $\beta$-redex that appears. This instantiation
and reduction process is repeated
until there are no more top-level $\beta$-redexes and the head is
not a variable bound to some term. Then the term with shorter
$\lambda$ prefix is expanded (only on the top-level) so that both have the
same length of $\lambda$ prefix. Finally, the $\lambda$ prefix is ignored, and we
focus only on the body. In this way, we avoid fully substituting
and normalizing terms and perform just enough operations
to determine the next step of the procedure.

If either term of the constraint is flex, we first invoke oracles to solve the
constraint. \ehohii{} implements the most efficient oracles implemented in
Zipperposition:\ fixpoint and pattern oracle (Sect.~\ref{sec:unif:implementation}). An oracle can return three results:
(1)~there is an MGU for the pair (\cn{Unifiable}), which is recorded in
\emph{subst}, and the next pair in $\emph{constraints}$ is tried;
(2)~no MGU exists
for the pair (\cn{NotUnifiable}), which causes the iterator to backtrack;
% to previous state;
(3)~if the pairs do not belong to the subclass that oracle
can solve (\cn{NotInFragment}), we generate possible variable bindings---that is,
we guess the approximate form of the solution.

\ehohii{} has a special module that generates bindings (\cn{NextBinding}). This
module is given the current constraint and the values of \emph{branch\_iter} and
\emph{steps}, and it either returns the next binding and the new values of
\emph{branch\_iter} and \emph{steps} or reports that all different variable
bindings are exhausted. The bindings that \ehohii{}'s unification procedure creates
are imitation, Huet-style projection, identification, and elimination (one
argument at a time) (Sect.~\ref{sec:unif:the-unification-procedure}). A limit on the
total number of applied binding rules can be set, as well as a limit on the
number of individual rule applications. The binding module checks whether limits
are reached using the iterator's \vn{steps} field.

Computing bindings is the only point in the procedure where the search tree
branches and different possibilities are explored. Thus, when \ehohii{} follows
the branch indicated by the binding module, it records the state to which it
needs to return, should the followed branch be backtracked. Therese are values
of $\vn{constraints}, \vn{steps}$, and $\vn{subst}$ before the branch is followed
and the value of the \vn{branch\_iter} that points past the followed branch. The
values of \vn{branch\_iter} are either \cn{BindBegin}, which denotes that no
binding was created, intermediate values that \cn{NextBinding} uses to remember
how far through bindings it is, and \cn{BindEnd}, which indicates that all
bindings are exhausted.

If all bindings are exhausted, the procedure checks whether the pair is
flex--flex and both sides have the same head. If so, the pair is decomposed and
constraints are derived from the arguments of the pair. Otherwise, the iterator
backtracks.
% @PETAR(actually the procedure applies bindings to same-head flex-flex pairs,
% so the text is OK -- we do get "stuck" enumerating those flex-flex pairs. The
% limits help here): Maybe explain here that you don't want a pragmatic prover
% like lambdaE to get stuck in wildly explosive flex-flex pairs? --JB
%
If the constraint is rigid--rigid, for unification to succeed the heads of both
sides of the constraint must be the same. Unification then continues
with new constraints derived from the arguments. Otherwise, the iterator must be
backtracked.

\ourpara{Matching} In Ehoh, the matching algorithm is mostly used inside
simplification rules such as demodulation and subsumption \cite{ss-02-brainiac}.
As these rules must be efficiently performed, using any complex matching
algorithm is not a viable option. Instead, we implemented a matching algorithm
for the pattern class of terms \cite{tn-93-patterns} to complement Ehoh's
$\lambda$-free higher-order matching algorithm \cite[Sect.~4]{section-ehoh}.
A term is a \emph{pattern} if each of its free variables either
has no arguments (as in first-order logic) or is applied to distinct De Bruijn
indices.

To determine which of the two algorithms to call (pattern or $\lambda$-free), we
added a cached property \texttt{HasNonPatternVar}, which is set for terms of the
form $X \,
\overline{s}_n$ where $n>0$ and either there exists some $s_i$ that is not a De Bruijn
index or there exist indices $i < j$ such that $s_i = s_j$ is
a De Bruijn index. This property is propagated to the superterms when they are
perfectly shared. This allows later checks if a term belongs to the pattern
class to be performed in constant time.

% When we need to determine if one term matches the other one we first check if
% any of them has a non-pattern applied variables. If so, $\lambda$-free
% higher-order matching is tried. This algorithm is adjusted to treat $\lambda$ prefixes
% as above in unification algorithm (ensuring that $\beta$-redexes can never occur)
% and that free variables are never bound to terms that have loose bound variables.
% Else if the terms have only pattern variables,
% pattern matching algorithm is tried. Note that in this sense, first-order order
% terms behave as pattern terms and thus pattern matching algorithm is run on
% them. For example, on terms $(X \, \cst{b}, \cst{f} \, \cst{a} \, \cst{b})$
% $\lambda$-free matching algorithm is invoked; on $(\cst{f} \, (\lambda x. \,
% \lambda y.\, X \, x), \cst{f} \, \cst{g})$ pattern matching is tried.

We have modified the $\lambda$-free higher-order matching algorithm to treat
$\lambda$ prefixes as above in unification procedure---by bringing the prefixes
to the same length and ignoring them afterwards. This ensures that the
algorithm will never try to match a free variable to a $\lambda$-abstraction,
making sure that $\beta$-redexes never appear (as in original $\lambda$-free
higher-order matching). We also modified the algorithm to ensure that free variables
are never bound to terms that have loose bound variables. This algorithm cannot
find many complex matching substitutions (matchers), but it can
efficiently determine whether two terms are variable renamings of each other
or whether a simple matcher can be used as in the case of $(X \, (\lambda x. \,x) \,
\cst{b}, \cst{f} \, (\lambda x. \,x) \, \cst{b})$, where ${X \mapsto \cst{f}}$ is
usually the desired matcher. If this algorithm does not find a matcher and both
terms are patterns, pattern matching is tried.

\ourpara{Indexing} Ehoh, like other modern theorem provers, efficiently retrieves
unifiable or matchable pairs of terms using indexing data structures. To find
terms unifiable with a query term or instances of a query term it uses
\emph{fingerprint indexing} \cite{ss-12-fp-indexing}. We extended this data
structure to support (full) higher-order terms in Zipperposition
\cite[Sect.~6]{unif-section}. We used the same approach in \ehohii{},
and we extended feature vector indices \cite{ss-2013-feature-vector}
in the same way.

Ehoh uses \emph{perfect discrimination trees} \cite{mcc-92-pdts} to find
generalizations of the query term (i.e., terms of which the query term is an instance).
This data structure is a trie
that indexes terms by representing them in a serialized, flattened form.
%\begin{rep}, where each node corresponds to a symbol in a term\end{rep}.
The left branch from the root in Figure \ref{fig:pdt} shows how the first-order terms
$\cst{f}\, \cst{a} \, X$ and $\cst{f}\, \cst{a} \, \cst{a}$ are stored.
In Ehoh, this data structure is extended to support partial application
and applied variables \cite{section-ehoh}.

\begin{figure}[tb]
\centering
\begin{tikzpicture}[level distance=3em, sibling distance=7.5em,
  %  edge from parent path={(\tikzparentnode.south) -- ++(0,-0.5em)
  %   -| (\tikzchildnode.north)},
    every node/.style = {shape=rectangle, rounded corners=.75em, minimum size=1.75em, draw, align=center}]
    \node {\phantom{x}}
      child { node {$\cst{f}$}
        child[sibling distance=2.5em] { node %[fill=verylightgray]
          {$\cst{a}$}
          child {node {$X$}}
          child {node {$\cst{a}$}} }
      }
      child { node {$\cst{g}$}
        child {node {$X \, \cst{a} \, \cst{b}$}
               child {node {$\cst{c}$}}}
      }
      child { node {$\cst{h}$}
        child {node {$\internallam_\iota$}
          child {node {$\internallam_\iota$}
            child {node {$X \, \db{0} \, \db{1}$}}
          }
      }}
      ;
\end{tikzpicture}
\caption{First-order, $\lambda$-free higher-order, and higher-order pattern
  terms in a perfect discrimination tree}
\label{fig:pdt}
\end{figure}

In \ehohii{}, we extended this structure to support $\lambda$-abstractions and
the higher-order pattern matching algorithm.
To this end, we changed the way in which terms are
serialized. First, we require that all terms are fully $\eta$-expanded (except
for arguments of variables applied in patterns). Then, when the term is serialized,
we dedicate a separate node for applied variable terms $X \, \overline{s}_n$,
instead of the node for $X$ followed by nodes for serialization of arguments
$\overline{s}_n$. We serialize $\lambda$-abstraction $\lambda x.\, s$ using
a special node $\internallam_\tau$, where $\tau$ is the type of $x$,
followed by the serialization of $s$. Other than these two changes, serialization
remains as in Ehoh, following the gracefulness principle.
Figure \ref{fig:pdt} shows how $\cst{g} \,
(X\,\cst{a}\,\cst{b}) \, \cst{c}$ and $\cst{h} \, (\lambda x. \, \lambda y. \, X
\, y \, x)$ are serialized.

Since the terms are stored in serialized form, it is hard to manipulate
$\lambda$ prefixes of stored terms during matching. Performing $\eta$-expansion
when serializing terms makes sure that matchable terms have
$\lambda$ prefixes of the same length.

We have dedicated separate nodes for applied variables because access to arguments
of applied variable is necessary for the pattern matching algorithm. Even though
arguments can be obtained by querying the arity $n$ of the variable and taking
next $n$ arguments in the serialization, this is both inefficient and inelegant.
As for De Bruijn indices, we treat them the same as function symbols and assign
them their own nodes.

\newcommand{\tstack}{\ensuremath{\texttt{term\_stack}}}
\newcommand{\tproc}{\ensuremath{\texttt{term\_proc}}}

Following the notation from the extension of perfect discrimination trees to
$\lambda$-free higher-order logic \cite{section-ehoh}, we now describe how enumeration of
generalizations is performed. To traverse the tree, \ehohii{} begins at the root
node and maintains two stacks:\ \tstack{} and \tproc{}, where \tstack{} contains the
subterms of the query term that have to be matched, and \tproc{} contains
processed terms that are used to backtrack to previous states. Initially,
\tstack{} contains the query term, the current matching substitution
$\sigma$ is empty, and the successor node is chosen among the child nodes as
follows:

\begin{enumerate}
\item[A.] If the node is labeled with a symbol $\xi$ (where
  $\xi$ is either a De Bruijn index or a constant) and the top item $t$
  of \tstack{} is of the form $\xi \, \overline{t}_n$, replace $t$ by
  $n$~new items $t_1,\dots,t_n$, and push $t$ onto \tproc{}.
\smallskip
\item[B.] If the node is labeled with a symbol $\internallam_\tau$ and the top
  item $t$ of \tstack{} is of the form $\lambda x.\, s$ and the type of $x$ is
  $\tau$, replace $t$ by $s$, and push $t$ onto \tproc{}.
\smallskip
\item[C.] If the node is labeled with a possibly applied variable $X \, \overline{s}_n$
  (where $n \geq 0$), and the top item of \tstack{} is $t$, the 
  matching algorithm described above is run on $X \, \overline{s}_n$ and $t$.
  The algorithm takes into account $\sigma$ built so far and extends it
  if necessary. If the algorithm succeeds, pop $t$ from \tstack{}, push it onto \tproc{},
  and save the original value of $\sigma$ in the node.
\end{enumerate}
  
Backtracking works in the opposite direction: If the current node is labeled with a De
Bruijn index or function symbol node of arity $n$, pop $n$ terms from \tstack{} and move
top of \tproc{} to \tstack{}. If the node is labeled with
$\internallam_\tau$, pop the top of \tstack{} and move the top of \tproc{} to
\tstack{}. Finally, if the node is labeled with a possibly applied variable, move top of the
\tproc{} to \tstack{} and restore the value of $\sigma$.

As an example of how finding a generalization works, consider the following
states of stacks and substitutions, which emerge when looking for generalizations of 
$\cst{g} \, (\cst{f} \, \cst{a} \, \cst{b}) \, \cst{c}$ in the tree of Figure \ref{fig:pdt}:
%
\[\begin{array}{@{}l@{\kern1em}l@{\kern1em}l@{\kern1em}l@{\kern1em}l@{}}
             & \epsilon                                                & \cst{g}                                                 & \cst{g}.(X \, \cst{a} \, \cst{b})                                                          & \cst{g}.(X \, \cst{a} \, \cst{b}).\cst{c} \\[.5\jot]
  \sigma{:}  & \emptyset                                               & \emptyset                                               & \{X \mapsto \cst{f}\}                                                                      & \{X \mapsto \cst{f}\} \\
  \tstack{:} & [\cst{g} \, (\cst{f} \, \cst{a} \, \cst{b}) \, \cst{c}] & [\cst{f} \, \cst{a} \, \cst{b}, \cst{c}]                & [\cst{c}]                                                                                  & [] \\
  \tproc{:}  & []                                                      & [\cst{g} \, (\cst{f} \, \cst{a} \, \cst{b}) \, \cst{c}] & [\cst{f} \, \cst{a} \, \cst{b}{,}\; \cst{g} \, (\cst{f} \, \cst{a} \, \cst{b}) \, \cst{c}] & [\cst{c}{,}\;\cst{f} \, \cst{a} \, \cst{b}{,}\; \cst{g} \, (\cst{f} \, \cst{a} \, \cst{b}) \, \cst{c}]
  \end{array}\]
