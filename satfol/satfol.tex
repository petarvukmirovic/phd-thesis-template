\chapter{SAT-Inspired Eliminations for Superposition}
\setheader{SAT-Inspired Eliminations for Superposition}
\label{ch:satfol}

\excludeversion{conf}
\includeversion{rep}
\includeversion{noqle}
\excludeversion{qle}
\newcommand{\paper}[0]{chapter}
\newcommand{\cor}{\ensuremath{\mathrel{\lor}}}
\newcolumntype{d}{D{.}{.}{0}}
\definecolor{light-gray}{gray}{0.925}
\newcommand\MAX[1]{\smash{\setlength{\fboxsep}{.3ex}\colorbox{light-gray}{\ensuremath{\vphantom{('q}{#1}}}}}




\authors{
    Joint work with\\
    Jasmin Blanchette
    and Marijn J.H. Heule
}

\begin{abstract}
Optimized SAT solvers simplify the clause set not only during preprocessing, but
they also simplify it during solving. This interleaving of
simplification and solving is called inprocessing. Some preprocessing
techniques have been generalized to first-order logic with equality. In this
\paper, we port inprocessing techniques to work with superposition, a leading
first-order proof calculus, and strengthen known preprocessing techniques.
Specifically, we look into elimination of hidden literals, variables
(predicates), and blocked clauses. Our evaluation using the Zipperposition
prover confirms that the new techniques usefully supplement the existing
superposition machinery.
\end{abstract}

\blfootnote{In this work I was the main designer of all the presented techniques.
Marijn Heule did weekly supervision and provided his knowledge of SAT solving to 
guide the design of all techniques. Jasmin Blanchette found the exact conditions
under which superposition remains complete when the predicate elimination rule is added
to the calculus. I also implemented and evaluated all the techniques. 
}

\newpage

\section{Introduction}
\label{sec:satfol:introduction}

Automated reasoning tools have become much more powerful in the last few decades,
thanks to procedures such as conflict-driven clause learning (CDCL)
\cite{MSLM09HBSAT} for propositional logic and superposition for first-order
logic with equality. However, the effectiveness of these procedures crucially
depends on how the input problem is represented as a clause set. The clause set
can be optimized beforehand (\emph{preprocessing}) or during the execution of
the procedure (\emph{inprocessing}). In this \paper, we lift several
preprocessing and inprocessing techniques from propositional logic to clausal
first-order logic, and demonstrate their usefulness in a superposition prover.

For many years, SAT solvers have used inexpensive clause simplification
techniques such as \emph{hidden literal} and \emph{hidden tautology elimination}
\cite{hjb-2010-cl-elim,hjb-2011-big-simplification} and \emph{failed literal
detection} \cite[Sect.~1.6]{jwf-1995-fld}. We generalize these techniques to
first-order logic with equality
(Sect.~\ref{sec:satfol:hidden-literal-based-elimination}). Since the generalization
involves reasoning about infinite sets of literals, we propose restrictions to
make them usable.

\emph{Variable elimination}, based on Davis--Putnam resolution \cite{dp-60-dp}, has
been studied in the context of both propositional logic
\cite{sp-04-niver,cs-00-zres} and quantified Boolean formulas (QBFs)
\cite{ab-2004-re}. The basic idea is to resolve all clauses with negative
occurrences of a propositional variable (i.e., a nullary predicate symbol) against
clauses with positive occurrences and delete the parent clauses. E\'en and
Biere \cite{eb-2005-satpreprocess} refined the technique to identify a subset
of clauses that effectively define a variable and use it to further optimize the
clause set. This latter technique, \emph{variable elimination by substitution},
has been an important preprocessor component in many SAT solvers since its
introduction in 2004.

\begin{sloppypar}
    Specializing second-order quantifier elimination
    \cite{go-1992-so-pred-elim,hjo-1996-scan}, Khasidashvili and Korovin~\cite{kk-2016-pe-fol} adapted variable elimination to preprocess first-order
    problems, yielding a technique we call \emph{singular predicate elimination}. We
    extend their work along two axes (Sect.~\ref{sec:satfol:predicate-elimination}): We
    generalize E\'en and Biere's refinement to first-order logic, resulting in
    \emph{defined predicate elimination}, and explain how both types of predicate
    elimination can be used during the proof search as inprocessing.    
\end{sloppypar}

\begin{qle}
It is well known that clauses containing \emph{pure literals}---predicate
literals whose root symbol occurs only with one polarity in the problem---can
be eliminated. We propose a generalization of this technique, under the name
\emph{quasipure literal elimination}, to allow the elimination of some bipolar
literals as well (Sect.~\ref{sec:satfol:quasipure-literal-elimination}).
\end{qle}

The last technique we study is \emph{blocked clause elimination} (Sect.\
\ref{sec:satfol:satisfiability-by-clause-elimination}). It is used in both SAT
\cite{jbh-10-BCE} and QBF solvers \cite{bls-11-bloqqer}. Its generalization to first-order
logic has produced good results when used as a preprocessor, especially on
satisfiable problems \cite{ksstb-2017-blockedfol}. We explore more ways to use
blocked clause elimination on satisfiable problems, including using it to
establish equisatisfiability with the empty clause set or as an inprocessing
rule. Unfortunately, we find that its use as inprocessing can compromise the
refutational completeness of superposition.


All techniques have been implemented in the Zipperposition prover
(Sect.~\ref{sec:satfol:implementation}), allowing us to ascertain their usefulness
(Sect.~\ref{sec:satfol:evaluation}). The best configuration solves \NumberOK{160}
additional problems on benchmarks consisting of all 13\,495 first-order TPTP theorems
\cite{gs-17-tptp}. The raw experimental data are publicly available.%
\footnote{\url{https://doi.org/10.5281/zenodo.4552499}}\confrep{
More details, including all the proofs, can be found in a
technical report \cite{our-report}.}{}

\section{Preliminaries}
\label{sec:satfol:preliminaries}

% \ourpara{Clausal First-Order Logic}%
Our setting is many-sorted (i.e., many-typed), first-order
logic~\cite{jg-1987-logic-textbook} with interpreted equality and a
distinguished type (or sort) $o$. We introduced this logic in
Sect.~\ref{sec:pre:fol} and here we use the same notation introduced in that section.
We write $\cst{f}^i(s)$ for the $i$-fold application of an unary symbol
$\cst{f}$ (e.g., $\cst{f}^3(x) = \cst{f}(\cst{f}(\cst{f}(x)))$) and call nullary
function symbols \emph{constants}. In this chapter, propositional variables
(corresponding to predicate constants in first-order logic) are written as
$\cst{x}, \cst{y}, \cst{p}, \cst{q}, \ldots$, while first-order free variables
are written in lowercase as $x,y,z,\ldots$.

We assume the notion of substitution introduced in Sect.~\ref{sec:pre:fol}.
We extend the notation by writing a substitution $\{x_1 \mapsto t_1,
\ldots,\allowbreak x_n \mapsto t_n\}$ shortly as $\{ \tupleempty{x} \mapsto \tupleempty{t} \}$.
A substitution is a \emph{variable renaming} if it is a
bijection from a set of variables to a set of variables. Iterated, $i$-fold application 
of a nonidempotent application $\sigma$ is denoted by $\sigma^i$.


As we are working with clausal logic, we assume the clausal structure as defined
in Sect.~\ref{sec:pre:clauses}. In this section we use the uppercase letter $L$
to denote literals, as this is more customary in the related literature for
propositional logic. Recall that predicate literals  are encoded as
(dis)equations with equality. To simplify the notation in this chapter we write
predicate literals in unencoded form: Positive literal $\eqlit{s}{\itrue}$ is
written as $s$ and negative literal $\neqlit{s}{\top}$ is written as
$\negpredlit{s}$. Literals $\eqlit{s}{t}$ where neither $s$ nor $t$ have the
type $o$ are called \emph{functional}. Given a literal $L$, we overload notation
and write $\neglit{L}$ to denote its complement. Clauses are often defined as
sets of literals, but superposition needs multisets; with multisets, an instance
$\sigmacl{C}$ always has the same number of literals as $C$, a most convenient
property. Given a clause set $N$, $\binset{N}$ denotes the subset of its binary
clauses: $\binset{N} = \{ L_1 \cor L_2 \mid L_1 \cor L_2 \in N \}$.

We assume the natural extensions of domain, valuation, interpretation, and model
(as defined by Fitting \cite{mf-1996-fol}) from unsorted to many-sorted logic.
We also assume the notion of normal models from Sect.~\ref{sec:pre:fol} (with
corresponding notation) and extend it with the notion of \emph{canonical
models}: A canonical model $\ourmodel$ is a normal model such that for every
element $d$ in one of $\ourmodel$'s domains there exists a ground term $t$ such
that $\ourmodel$ interprets $t$ as $d$. 
We also make use of Herbrand models and Herbrand's theorem \cite[Sect.~5.4]{mf-1996-fol}.
In Herbrand models the domain consists of all ground terms. These models have a 
useful property that a formula is satisfiable if and only if it is satisfiable in an
Herbrand model. Herbrand's theorem states that every unsatisfiable clause set has (propositionally)
unsatisfiable ground instance.     
Canonical models generalize Herbrand models to first-order logic with equality.

All of the techniques described in this chapter are applied in the context of
first-order superposition which was introduced in Sect.~\ref{sec:pre:sup}. We
reuse all the notions introduced in this section and the corresponding notations. 

\section{Hidden-Literal-Based Elimination}
\label{sec:satfol:hidden-literal-based-elimination}

In propositional logic, binary clauses from a clause set $N$ can be used to
efficiently discover literals $L, L'$ for which the implication $L' \impl L$
is entailed by $N$'s binary clauses---i.e., $\binset{N} \models L' \impl L$.
Heule et al.\ \cite{hjb-2011-big-simplification} introduced the concept of \emph{hidden
literals} to capture such implications.

\begin{defi}
   Given a propositional literal $L$ and a propositional clause set~$N$, the
   set of \emph{propositional hidden literals} for $L$ and~$N$ is
   $\PHL(L, N) = \{ L' \mid L' \bigpimpl{N}^\ast L \} \setminus \{ L \}$, where $\bigpimpl{N}$ is
   defined so that $\neglit{L_1} \bigpimpl{N} L_2$ whenever $L_1 \cor L_2 \in N.$
   Moreover, $\PHL(L_1 \cor \cdots \cor L_n, N) = \bigcup_{i=1}^n
   \PHL(L_i, N)$.
\end{defi}

Heule et al.\ used a definition based on a fixpoint computation, but our
definition based on the reflexive transitive closure $\bigpimpl{N}^\ast$ of $\bigpimpl{N}$ is equivalent. Intuitively,
a hidden literal can be added to or removed from a clause without affecting its
semantics in models of~$N.$ By eliminating hidden literals from $C$, we simplify
it. By adding hidden literals to $C$, we might get a tautology $C'$ (i.e., a
valid clause:\ $\models C'$), meaning that $\binset{N} \models C$, thereby
enabling us to delete $C$. Note that $\PHL(L,N)$ is finite for a finite~$N.$

\begin{defi}
   \label{def:hle}\label{def:hte}
   Given $L' \cor L \cor C \in N,$ if $L' \in
   \PHL(L, N)$, \emph{hidden literal elimination} (HLE) replaces $N$ by $(N
   \setminus \{L' \cor L \cor C\}) \cup \{L \cor C\}$.
   Given $C \in N$, $\{L_1,\dots,L_n\} = \PHL(C, N)$, and $C' = C \cor L_1 \cor
   \cdots \cor L_n$, if $C'$ is a tautology, \emph{hidden
   tautology elimination} (HTE) replaces $N$ by $N \setminus \{C\}$.
\end{defi}

\begin{theorem}
   The result of applying HLE or HTE to a clause set $N$ is
   equivalent to $N$.
\end{theorem}

\begin{proof}
For HLE, if $L' \in \PHL(L, N)$,  $\binset{N} \models \neglit{L'} \cor L$. Then,
subsumption resolution (a sound rule that applies resolution followed by
subsumption \cite{bg-01-resolution}) yields shortened clause $L \cor C'$ from
Definition~\ref{def:hle}. For HTE, it can be shown that sets $N$ and $N
\cup \{ C' \} \setminus \{C\}$ are equivalent
\cite[Sect.~2.1]{hjb-2011-big-simplification}. As clause $C'$ is a tautology,
$N$ and $N \setminus \{C\}$ are equivalent.\qedhere
\end{proof}

We generalize hidden literals to first-order logic with equality by
considering substitutivity of variables as well as congruence of equality.

\begin{defi}
\label{def:hl-fo}
Given a literal $L$ and a clause set $N$,
the set of \emph{hidden literals} for $L$ and $N$
is $\HL(L,N) = \{ L' \mid L' \bigfimpl{N}^\ast L \} \setminus \{ L \}$, where
$\bigfimpl{N}$ is defined so that:
\begin{enumerate}
    \item $\sigmaterm{\neglit{L'}} \bigfimpl{N} \sigmaterm{L}$ if
    $L' \cor L \in N$ and $\sigma$ is a substitution
    \item $\eqlit{s}{t} \bigfimpl{N} \eqlit{u[s]}{u[t]}$ for all terms $s, t$ and
    contexts $u[\phantom{\cdot}]$
    \item $\neqlit{u[s]}{u[t]} \bigfimpl{N} \neqlit{s}{t}$ for all terms $s, t$ and
    contexts $u[\phantom{\cdot}]$
\end{enumerate}
% (1)~;
% (2)~; and
% (3)~.
Moreover, $\HL(L_1 \cor \cdots \cor L_n, N) = \bigcup_{i=1}^n \HL(L_i, N)$.
\end{defi}

\looseness=-1
The generalized definition also enjoys the key property that $L'
\in \HL(L, N)$ implies $\binset{N} \models L' \impl L$. However, $\HL(L, N)$
may be infinite even for predicate literals; for example,
$\pospredlit{\cst{p}(\cst{f}^i(x))} \in \HL(\pospredlit{\cst{p}(x)}, \{\pospredlit{\cst{p}(x)} \cor
\negpredlit{\cst{p}(\cst{f}(x))} \})$ for every $i$.

Based on Definition \ref{def:hl-fo}, we can generalize hidden literal elimination
and support a related technique:
\begin{align*}
    & \namedsimpsc{HLE}{L' \cor L \cor C}{L \cor C}{L' \in \HL(L,N)} \\[.5\jot]
    & \namedsimpsc{\rlap{FLE}\phantom{HLE}}{L \cor C}{C}{L',\neglit{L'} \in \HL(\neglit{L}, N)}
 \end{align*}
Recall that double lines denote simplification rules (Sect.~\ref{sec:pre:sup}).
The second rule is called \textit{failed literal elimination},
inspired by the SAT technique of asserting $\neglit{L}$ if $L$ is a \textit{failed literal} \cite{jwf-1995-fld}.
It is easy to see that rule \infname{HLE} is sound.
From $L' \in \HL(L,N)$ we have $N \models L' \impl L$ (i.e., $\neglit{L'} \cor L$).
Performing subsumption resolution \cite{bg-01-resolution} between $L'
\cor L \cor C$ and $\neglit{L'} \cor L$ yields the conclusion, which is
therefore entailed by $N.$ For \infname{FLE}, the condition $L',
\neglit{L'} \in \HL(\neglit{L},N)$ means that $\binset{N} \models \{\neglit{L'} \cor
\neglit{L}{,}\; L' \cor \neglit{L}\} \models \neglit{L}$.


\begin{exa}
   \label{example:hle}
   Consider the clause set $N = \{ \cst{p}(x) \cor \neglit{\cst{p}(\cst{f}(x))}{,}\;
   \cst{p}(\cst{f}(\cst{f}(x))) \cor \eqlit{\cst{a}}{\cst{b}} \}$ and the clause
   $C = \neqlit{\cst{f}(\cst{a})}{\cst{f}(\cst{b})} \cor \cst{p}(x)$. The first
   clause in $N$ induces $\cst{p}(\cst{f}(x)) \bigfimpl{N} {\cst{p}(x)}$,
   $\cst{p}(\cst{f}(\cst{f}(x))) \bigfimpl{N} \cst{p}(\cst{f}(x))$, and
   hence $\cst{p}(\cst{f}(\cst{f}(x))) \bigfimpl{N}^\ast  \cst{p}(x)$.
   Together with the second clause in $N$, it can be used to derive $\neqlit{\cst{a}}{\cst{b}}
   \bigfimpl{N}^\ast  \cst{p}(x)$. Finally, using rule 3 of Definition
   \ref{def:hl-fo}, we derive $\neqlit{\cst{f}(\cst{a})}{\cst{f}(\cst{b})}
   \bigfimpl{N}^\ast  \cst{p}(x)$---that is,
   $\neqlit{\cst{f}(\cst{a})}{\cst{f}(\cst{b})} \in \HL(\cst{p}(x), N)$. This
   allows us to remove $C$'s first literal using \infname{HLE}.
\end{exa}

Two special cases of \infname{HLE} exploit equality congruence as embodied by
conditions 2 and 3 of Definition~\ref{def:hl-fo} without requiring to
compute the $\HL$~set:
\begin{align*}
  %% TYPESETTING: \,'s below
  \namedsimp{CongHLE$^+$}{\eqlit{s}{t} \cor \eqlit{u[s]}{u[t]} \cor C}{\eqlit{u[s]}{u[t]} \cor C}\,\, \\[.5\jot]
  \namedsimp{CongHLE$^-$}{\neqlit{s}{t} \cor \neqlit{u[s]}{u[t]} \cor C}{\neqlit{s}{t} \cor C}
\end{align*}%

Hidden literals can be combined with unit clauses~$L'$ to remove more literals:
\[\namedsimpsc{UnitHLE}{L' \quad L \cor C}{L' \quad C}{\sigmaterm{L'} \in \HL(\neglit{L},N)}
%\text{~for some~}\sigma -- %%% Not necessary in a rule -- all variables are universally quantified. --JB
\]
%
Given a unit clause $L' \in N$, the rule uses $L'$ to discharge $\sigmaterm{L'}$ in
$N \models \sigmaterm{L'} \impl \neglit{L}$. As a result, we have $N \models
\neglit{L}$, making it possible to remove $L$ from $L \cor C$.

% Kiesl and Suda described first-order generalization of {\it asymmetric literals}
% \cite{ks-2017-unif-principle}: literal $L\sigma$ is asymmetric for a clause $C$
% and a clause set $N$ if there exists a clause $D \cor \neglit{L} \in N \setminus
% \{C \}$ such that $D\sigma \subseteq C$ for some substitution $\sigma$. 

\begin{exa}
   \label{example:unithle}
   \looseness=-1
   Consider the clause set $N = \{\cst{p}(x) \cor \cst{q}(\cst{f}(x)){,}\;
   \neglit{\cst{q}(\cst{f}(\cst{a}))} \cor \eqlit{\cst{f}(\cst{b})}{\cst{g}(\cst{c})}{,}\;
   \neqlit{\cst{f}(x)}{\cst{g}(y)}\}$ and the clause $C = \neglit{\cst{p}(\cst{a})} \cor
   \neglit{\cst{q}(\cst{b})}$. The first clause in $N$ induces
   $\neglit{\cst{q}(\cst{f}(\cst{a}))} \bigfimpl{N} \cst{p}(\cst{a})$, whereas
   the second one induces $\neqlit{\cst{f}(\cst{b})}{\cst{g}(\cst{c})} \bigfimpl{N}
   \neglit{\cst{q}(\cst{f}(\cst{a}))}$. Thus, we have $\neqlit{\cst{f}(\cst{b})}{\cst{g}(\cst{c})}
   \bigfimpl{N}^\ast \cst{p}(\cst{a})$---that is, $\neqlit{\cst{f}(\cst{b})}{\cst{f}(\cst{c})} \in
   \HL(\cst{p}(\cst{a}), N)$. By applying the substitution $\{x \mapsto \cst{b}{,}\allowbreak\; y
   \mapsto \cst{c}\}$ to the third clause in $N$, we can fulfill the conditions of
   \infname{UnitHLE} and remove $C$'s first literal.
\end{exa}

Next, we generalize hidden tautologies to first-order logic.

\begin{defi}
   A clause $C$ is a \emph{hidden tautology} for a clause set $N$ if there
   exists a finite set $\{L_1,\dots,L_n\} \subseteq \HL(C,N)$ such that
   $C \cor L_1 \cor \cdots \cor L_n$ is a tautology.
\end{defi}

\begin{exa}
   \label{example:hidden-tautologies-completeness}
   \looseness=-1
   In general, hidden tautologies are not redundant and cannot be deleted during saturation.
   Consider the unsatisfiable set $N = \{ \negpredlit{\cst{a}}{,}\;
   \negpredlit{\cst{b}}{,}\; \pospredlit{\cst{a}} \cor
   \pospredlit{\cst{c}}{,}\allowbreak\; \pospredlit{\cst{b}} \cor \negpredlit{\cst{c}}
   \}$, the order $\cst{a} \prec
   \cst{b} \prec \cst{c}$, and the empty selection function. The
   only possible superposition inference from $N$ is between the last two clauses,
   yielding the hidden tautology $\pospredlit{\cst{a}} \cor \pospredlit{\cst{b}}$
   (after simplifying away $\neqlit{\top}{\top}$), which is entailed by the larger
   clauses $\pospredlit{\cst{a}} \cor \pospredlit{\cst{c}}$ and
   $\pospredlit{\cst{b}} \cor \negpredlit{\cst{c}}$. If this clause is removed,
   the prover could enter an infinite loop, forever generating and deleting the
   hidden tautology\confrep{}{ and never getting the opportunity to derive the
   empty clause}.
\end{exa}

\begin{rep}
   \newcommand{\aset}{\mathcal{A}}
   \newcommand{\pset}{\mathcal{P}}
   
   In practice, most provers use a variant of the given clause procedure.
   Removing hidden tautologies breaks the invariant of the procedure that all
   inferences between clauses in $\aset$ are redundant. The end result is not
   that the prover diverges, but that it terminates without deriving the empty
   clause.

   To observe this, assume the setting as in Example
   \ref{example:hidden-tautologies-completeness}, and let $\pset=N$ and
   $\aset=\emptyset$. After moving the first three clauses from $\pset$ to
   $\aset$ ($\aset = \{ \negpredlit{\cst{a}}, \negpredlit{\cst{b}}, \pospredlit{\cst{a}} \cor
   \pospredlit{\cst{c}} \}$, $\pset = \{\pospredlit{\cst{b}} \cor \negpredlit{\cst{c}}\}$), 
   no inferences are possible, and no new clauses are added to $\pset$. After the last clause
   is moved to $\aset$, the hidden tautology $\pospredlit{\cst{a}} \cor \pospredlit{\cst{b}}$
   is produced. If it is deleted, the prover terminates with the unsatisfiable set $\aset$,
   but does not derive the empty clause. 
\end{rep}

To delete hidden tautologies during saturation, the prover could check that all
the relevant clause instances encountered along the computation of $\HL$ are
$\prec$-smaller than a given hidden tautology. However, this would be expensive
and seldom succeed, given that superposition creates lots of nonredundant
hidden tautologies. Instead, we propose to simplify hidden tautologies using the
following rules:
%
%\begin{linenomath*}
% \begin{align*}
%    %% TYPESETTING: \,'s below
%    \namedsimpsc{HTR}{L \cor L' \cor C}{L \cor L'}{\neglit{L'} \in \HL(L, N)} &\\
%    \namedsimpsc{FLR}{L \cor C}{L}{L',\neglit{L'} \in \HL(L, N)} &
% \end{align*}
%
\begin{align*}
   & \namedsimpsc{HTR}{L \cor L' \cor C}{L \cor L'}{\neglit{L'} \in \HL(L, N) \text{~and~} C \not= \bot} \\[.5\jot]
   & \namedsimpsc{\rlap{FLR}\phantom{HTR}}{L \cor C}{L}{L',\neglit{L'} \in \HL(L, N) \text{~and~} C \not= \bot}
\end{align*}
%

%\end{linenomath*}
%
We call these techniques \emph{hidden tautology reduction} and \emph{failed literal
reduction}, respectively.
% \infname{FLD} is inspired by the \confrep{}{eponymous }SAT
% approach of asserting $L$ if $\neglit{L}$ is determined to be a failed literal
% \cite{jwf-1995-fld}.
%
Both rules are sound.
%
As with hidden literals, unit clauses~$L'$ can be exploited:
\[\namedsimpsc{UnitHTR}{L' \quad L \cor C}{L' \quad L}{\sigmaterm{L'} \in \HL(L,N) \text{~and~} C \not= \bot}
%\text{~for some~}\sigma
\]

We give the simplification rules above\confrep{}{ (for hidden literal
elimination, hidden tautology reduction,
failed literal detection, and their variants)} the collective name of
\emph{hidden-literal-based elimination} (HLBE).
Yet another use of hidden literals is for \emph{equivalent literal
substitution} \cite{hjb-2010-cl-elim}: If both $L' \in \HL(L, N)$ and $L
\in \HL(L', N)$, we can often simplify $\sigmacl{L'}$ to $\sigmacl{L}$ in $N$ if
$\sigmacl{L'} \succ \sigmacl{L}$. We want to investigate this~further.

% \looseness=-1
% Provers based on the DISCOUNT loop use only active clauses for
% simplification. If we restrict our attention to a finite subset of hidden
% literals, we can organize them into data structures that support efficient
% lookup of a hidden literal. Efficient implementation of these data structures
% allows to use all passive clauses for simplification, strengthening DISCOUNT
% loop simplification machinery.

\begin{theorem}
\begin{sloppypar}
The rules \infname{HLE}, \infname{FLE}, \infname{CongHLE$^+$},
\infname{Cong\allowbreak HLE$^-$}, \infname{UnitHLE}, \infname{HTR},
\infname{FLR}, and \infname{UnitHTR} are sound simplification rules.
\end{sloppypar}
\end{theorem}

\begin{rep}
\begin{proof}
It is easy to see that the deleted premises are entailed by the conclusions that
replace them and that the conclusions' instances are $\prec$-smaller than the
premises' instances, as required by the redundancy criterion. It remains to
check soundness.

\medskip

\noindent
\textsc{Case} \infname{HLE}:\enskip
We have $N{,}\> L' \models L$ by the side condition and must show
$N{,}\> L' \lor L \lor C \models L \lor C$. Let
$\ourmodel \models N{,}\> L' \lor L \lor C$. If $\ourmodel \models L'$, then
we also have $\ourmodel \models L$ thanks to the side condition and hence
$\ourmodel \models L \lor C$. Otherwise, we have $\ourmodel \models L \lor C$,
which is exactly what we need to show.

\medskip

\noindent
\textsc{Case} \infname{FLE}:\enskip
We have $N{,}\> L \models L'$ and $N, L \models \lnot L'$ by the side condition.
If $\ourmodel \models N{,}\> L$, then both $\ourmodel \models L'$ and
$\ourmodel \models \lnot L'$, an absurdity.
Otherwise, we have $\ourmodel \models C$, as desired.

\medskip

\noindent
\textsc{Case} \infname{CongHLE$^+$}, \infname{CongHLE$^-$}:\enskip
Obvious by congruence of equality.

\medskip

\noindent
\textsc{Case} \infname{UnitHLE}:\enskip
We have $N{,}\> L \models \lnot \sigmaterm{L'}$ by the side condition. If $\ourmodel
\models N{,}\> L$, then $N \models \lnot \sigmaterm{L'}$. But since $L' \in N$, this is
an absurdity. Otherwise, we have $\ourmodel \models C$, as desired.

\medskip

\noindent
\textsc{Case} \infname{HTR}:\enskip
We have $N{,}\> \lnot L' \models L$ by the side condition. If either $\ourmodel
\models L$ or $\ourmodel \models L'$, the desired result follows directly.
Otherwise, from $\ourmodel \models \lnot L'$ we also have $\ourmodel \models L$
thanks to the side condition, contradicting $\ourmodel \models \lnot L$.

\medskip

\noindent
\textsc{Case} \infname{FLR}:\enskip
We have $N{,}\> L' \models L$ and $N{,}\> \lnot L' \models L$ by the side condition.
Hence $N \models L$, as desired.

\medskip

\noindent
\textsc{Case} \infname{UnitHTR}:\enskip
We have $N{,}\> \sigmaterm{L'} \models L$. Since $L' \in N$, we have $N \models L$,
as desired.
\qedhere
\end{proof}
\end{rep}

\section{Predicate Elimination}
\label{sec:satfol:predicate-elimination}

For propositional logic, variable elimination \cite{eb-2005-satpreprocess} is
one of the main preprocessing and inprocessing techniques. Following Gabbay and Ohlbach's ideas
\cite{go-1992-so-pred-elim}, Khasidashvili and Korovin \cite{kk-2016-pe-fol}
generalized variable elimination to first-order logic with equality and
demonstrated that it is effective as a preprocessor. We propose an improvement
that makes this applicable in more cases and show that, with a minor
restriction, it can be integrated in a superposition prover
without compromising its refutational completeness.

\subsection{Singular Predicates}

Khasidashvili and Korovin's preprocessing technique removes singular predicates
(which they call ``non-self-referential predicates'') from the problem using
so-called flat resolution.

\begin{defi}
   A predicate symbol is called \emph{singular}\confrep{ (or ``non-self-referential'')}{}
   for a clause set $N$ if it occurs at most once in every clause contained in
   $N.$
\end{defi}

\begin{defi}
   \label{def:flat-res}
   Let $C = \pospredlit{\cst{p}(\tuplen{s})} \cor C'$ and $D =
   \negpredlit{\cst{p}(\tuplen{t})} \cor D'$ be clauses with no variables in
   common. The clause $\neqlit{s_1}{t_1} \cor \cdots \cor \neqlit{s_n}{t_n}
   \cor C' \cor D'$ is a \emph{flat resolvent} of $C$ and $D$ on $\cst{p}$.
\end{defi}

% Predicate elimination saturates with respect to flat resolvents, removing all
% clauses containing $\cst{p}$. Given two (possibly identical) clause sets $M, N$,
% the resolved set $M \flatres_{\!\cst{p}} N$, defined below, repeatedly draws
% one inference partner from $M$ and the other one from $N$.

Given two (possibly identical) clause sets $M, N$, predicate elimination
iteratively replaces clauses from $N$ containing the symbol $\cst{p}$ with all flat
resolvents against clauses in $M$. Eventually, it yields a
set with no occurrences of $\cst{p}$.


\begin{defi}
\label{def:flat-res-set}
   Let $M, N$ be clause sets and $\cst{p}$ be a singular predicate for
   $M$. Let $\flatresiter$ be the following relation on clause set pairs and clause sets:
   \begin{enumerate}
   \item $(M{,}\> \{\arbpredlit{\cst{p}(\tupleempty{s})} \cor C'\} \uplus N) \flatresiter (M{,}\; N' \cup N)$ if
   $N'$ is the set that consists of all clauses (up to variable renaming) that are flat resolvents
   with $\arbpredlit{\cst{p}(\tupleempty{s})} \cor C'$ on $\cst{p}$ and a clause from $M$ as premises.
   The premises' variables are renamed apart.

   \smallskip
   \item $(M, N) \flatresiter N$ if $N$ has no occurrences of $\cst{p}$.
   \end{enumerate}
   \noindent  The \emph{resolved set} $M \flatres_{\!\cst{p}} N$ is the clause set $N'$ such that $(M,N) \flatresiter^* N'$.
   % obtained by the following
   % procedure: Set $N' = N$. Then repeatedly (1)~choose a clause $D \in N'$
   % containing $\cst{p}$, (2)~compute all flat resolvents involving $D$ and
   % partners from $M$, renaming variables apart, and (3)~replace $D$ with these
   % flat resolvents in $N'$. Stop when $N'$ contains no more occurrence of
   % $\cst{p}$.
\end{defi}

\pagebreak[2]

\begin{rep}
\begin{lemma}
   \label{lem:flat-res-set-termination-confluence}
   Let $M, N$ be clause sets and $\cst{p}$ be a singular predicate for
   $M$. The resolved set $N'$ is reached in a finite number of $\flatresiter$ steps,
   and it is unique up to variable renaming.
\end{lemma}
\begin{proof}
   To show $\flatresiter$ is terminating we use the following ordinal measure on
   clause sets: $\nu(\{D_1,\dotsc,\allowbreak D_n\}) = \omega^{\nu(D_1)} \oplus
   \cdots \oplus \omega^{\nu(D_n)}$, where $\nu(D)$ is the number of
   occurrences of $\cst{p}$ in $D$, $\omega$ is the first infinite ordinal, and
   $\oplus$ is the Hessenberg, or natural, sum, which is commutative.
   For every transition
   $(M, \{C\} \cup N) \flatresiter (M, N' \cup N)$, we have $\nu(\{C\} \cup N) > \nu(N' \cup N)$
   because $\omega^{\nu(C)} > \omega^{\nu(C)-1} \cdot |N'|$.
   Eventually, a state $(M,N')$ with $\nu(N')=\omega^0\cdot n$ is reached.
   Then, we apply the second rule of Definition \ref{def:flat-res-set} to obtain the resolved set $N'$.

   To show that $N'$ is unique, i.e., $\flatresiter$ is confluent, it suffices
   to show (since $\flatresiter$ is terminating and Newmann's lemma applies
   \cite{bn-98-tr-and-all-that}) that $\flatresiter$ is locally confluent. In
   other words, whenever $(M,N) \flatresiter (M, N_1)$ and $(M,N) \flatresiter
   (M, N_2)$, there exists $N'$ such that $(M, N_1) \flatresiter (M, N')$ and
   $(M, N_2) \flatresiter (M,N')$. 
   
   There are two main sources of nondeterminism of $\flatresiter$: The choice of $C
   \in N$ and the choice of a literal in $C$ to act on. Let us focus on the choice of
   $C$ in $N$; the same discussion applies for the choice of a literal in $C$.

   Let $N = \{C_1\} \uplus \{C_2\} \uplus N'$, where $C_1$ and $C_2$ are
   clauses with occurrences of $\cst{p}$. Then, $(M, \{C_1\} \uplus \{ C_2 \cup
   N' \}) \flatresiter (M, N'_1 \cup \{ C_2 \cup N'\})$ and $(M, \{C_2\} \uplus
   \{C_1 \cup N' \}) \flatresiter (M, N'_2 \cup \{ C_1 \cup N' \})$ where $N'_1$ and
   $N'_2$ are sets of corresponding resolvents. Both $\flatresiter$ steps can
   be joined (up to variable renaming) to $(M, N'_1 \cup N'_2 \cup N')$, showing
   that $\flatresiter$ is locally confluent.
\end{proof}
\end{rep}

\begin{conf}
The relation $\flatresiter$ is confluent up to variable renaming. Thanks to
the singularity constraint on $M$, it
also terminates on finite sets because the following ordinal measure decreases:
$\nu(\{D_1,\allowbreak\dotsc,\allowbreak D_n\}) = \omega^{\nu(D_1)} \oplus \cdots \oplus
\omega^{\nu(D_n)}$, where $\nu(D)$ counts the occurrences of $\cst{p}$ in
$D$, $\omega$ is the first infinite ordinal,
and $\oplus$ is the Hessenberg, or natural, sum, which is commutative.
For every transition
$(M, \{C\} \cup N) \flatresiter (M, N' \cup N)$, we have
$\nu(\{C\}) = \omega^{\nu(C)} > \omega^{\nu(C)-1} \cdot |N'| = \nu(N')$.
\end{conf}

Next, it is useful to partition
clause sets into subsets based on the presence and polarity of a singular
predicate.

\begin{defi}
   Let $N$ be a clause set and $\cst{p}$ be a singular predicate for
   $N.$ Let $\withpredpos{N}{\cst{p}}$ consist of all clauses of the form $\pospredlit{\cst{p}(\tuple{s}{})} \cor C' \in N$,
   let $\withpredneg{N}{\cst{p}}$ consist of all clauses of the form $\negpredlit{\cst{p}(\tuple{s}{})} \cor C' \in N$,
   let $\withpred{N}{\cst{p}} = \withpredpos{N}{\cst{p}} \cup \withpredneg{N}{\cst{p}}$,
   and let $\withoutpred{N}{\cst{p}} = N \setminus \withpred{N}{\cst{p}}$.
\end{defi}

\begin{defi}
   \label{def:pred-elim}
   Let $N$ be a clause set and $\cst{p}$ be a singular predicate for
   $N.$
   \emph{Singular predicate elimination} (SPE) of $\cst{p}$ in $N$ replaces $N$ by
   $\withoutpred{N}{\cst{p}} \cup (\withpredpos{N}{\cst{p}} \flatres_{\!\cst{p}} \withpredneg{N}{\cst{p}})$.
\end{defi}

The result of SPE is satisfiable if and only if $N$ is satisfiable
\cite[Theorem~1]{kk-2016-pe-fol}, justifying SPE's use in a preprocessor.
However, eliminating singular predicates aggressively can dramatically increase
the number of clauses. To prevent this, Khasidashvili and Korovin suggested to
replace $N$ by $N'$ only if $\lambda(N') \leq \lambda(N)$
and $\mu(N') \leq \mu(N)$, where
$\lambda(N)$ is the number of literals in~$N$ and
$\mu(N)$ is the sum for all clauses $C \in
N$ of the square of the number of distinct variables in $C$.

Compared with what modern SAT solvers use, this
criterion is fairly restrictive. We relax it to make it possible to
eliminate more predicates, within reason. Let $K_\mathrm{tol} \in \mathbb{N}$ be a tolerance
parameter. A predicate elimination
step from $N$ to $N'$ is allowed if
$\lambda(N') < \lambda(N) + K_\mathrm{tol}$ or
$\mu(N') < \mu(N)$ or
$|N'| < |N| + K_\mathrm{tol}$. Intuitively, we allow predicate elimination
even in the cases in which proof state increases in size, as long as we can control
this increase with the parameter $K_\mathrm{tol}$. 
A refinement, which we want to try out in future work, would be to gradually
increment the tolerance $K_\mathrm{tol}$, as is done in some SAT solvers.


\subsection{Defined Predicates}

SPE is effective, but an important refinement has not yet been adapted to
first-order logic:\ variable elimination by substitution. E{\'{e}}n and Biere
\cite{eb-2005-satpreprocess} discovered that a propositional variable~$\cst{x}$ can be
eliminated without computing all resolvents if it is expressible as an
equivalence $\cst{x} \medleftrightarrow \varphi$, where $\varphi$, the ``gate,''
is an arbitrary formula that does not reference~$\cst{x}$.
They partition a set $N$
\confrep{}{of propositional clauses }into a definition set $G$, essentially the
clausification of $\cst{x} \medleftrightarrow \varphi$, and
$R = \withpred{N}{\cst{p}} \setminus G$, the remaining
clauses containing~$\cst{p}$. To eliminate $\cst{x}$ from $N$ while
preserving satisfiability, it suffices to resolve clauses from $G$ against
clauses from $R$, effectively substituting $\varphi$ for $\cst{x}$ in $R$.
Crucially, we do not need to resolve pairs of clauses from $G$
or pairs of clauses from $R$.
We generalize this idea to first-order logic.

\begin{defi}
   \label{def:definition}
   \looseness=-1
   Let $G$ be a clause set and $\cst{p}$ be a predicate symbol.
%
   The set $G$ is a \emph{definition set} for $\cst{p}$ if
   \begin{enumerate}
      \item $\cst{p}$ is singular for $G$
      \item $G$ consists of clauses of the form
      $\arbpredlit{\cst{p}(\tupleempty{x})} \cor C'$ (up to variable renaming),
      where the variables $\tupleempty{x}$ are distinct
      \item the
      variables in $C'$ are all among $\cst{p}$'s arguments $\tupleempty{x}$
      \item all clauses in $\withpredpos{G}{\cst{p}}
      \flatres_{\!\cst{p}} \withpredneg{G}{\cst{p}}$ are tautologies
      \item $E(\tupleempty{\cst{c}})$ is unsatisfiable, where
      the \emph{environment} $E(\tupleempty{x})$ consists of all subclauses $C'$ of any
      $\arbpredlit{\cst{p}(\tupleempty{x})} \mathbin{\cor} C' \in G$ and
      $\tupleempty{\cst{c}}$ is a tuple of distinct fresh constants substituted
      in for $\tupleempty{x}$
   \end{enumerate}
\end{defi}

A definition set $G$ corresponds intuitively to a definition by
cases in mathematics---e.g.,
\[\cst{p}(\tuple{x}{}) =
\begin{cases} \top & \mathrm{if}~\varphi(\tuple{x}{}{}) \\[-\jot]
\bot & \mathrm{if}~\psi(\tuple{x}{})\end{cases}\]
Part~4 states that the case conditions are mutually exclusive
(e.g., $\neglit{\varphi(\tuple{x}{})} \lor \neglit{\psi(\tuple{x}{})}$),
and part~5 states that they are exhaustive
(e.g., $\nexists\tuple{\cst{c}}{} .\; \neglit{\varphi(\tuple{\cst{c}}{})} \land \neglit{\psi(\tuple{\cst{c}}{})}$).
%
Given a quantifier-free formula $\cst{p}(\tuple{x}{}) \medleftrightarrow
\varphi(\tuple{x}{})$ with distinct variables $\tuple{x}{}$ such that
$\varphi(\tuple{x}{})$ does not contain $\cst{p}$, any reasonable
clausification algorithm would produce a definition set for $\cst{p}$.

\begin{exa}
   \label{example:tautologies}
   Given the formula $\cst{p}(x) \medleftrightarrow \cst{q}(x) \mathrel\land
   (\cst{r}(x) \cor \cst{s}(x))$, a standard clausification algorithm
   \cite{nw-01-small-cnf} produces $\{ \negpredlit{\cst{p}(x)} \cor
   \pospredlit{\cst{q}(x)}{,}\; \negpredlit{\cst{p}(x)} \cor
   \pospredlit{\cst{r}(x)} \cor \pospredlit{\cst{s}(x)}{,}\;
   \pospredlit{\cst{p}(x)} \cor \negpredlit{\cst{q}(x)} \cor
   \negpredlit{\cst{r}(x)}{,}\; \pospredlit{\cst{p}(x)} \cor
   \negpredlit{\cst{q}(x)} \cor \negpredlit{\cst{s}(x)}\}$, which qualifies
   as a definition set for $\cst{p}$.
\end{exa}

Definition sets generalize E{\'{e}}n and Biere's
gates. They can be recognized syntactically for formulas such as
$\cst{p}(\tuple{x}{}) \medleftrightarrow \bigvee_{\!i} \cst{q}_i(\tuple{s_i}{})$ or
$\cst{p}(\tuple{x}{}) \medleftrightarrow \bigwedge_i \cst{q}_i(\tuple{s_i}{})$,
or semantically: Condition~4 can be checked
using the congruence closure algorithm, and condition~5 amounts to
a propositional unsatisfiability check.

The key result about propositional gates carries over to definition sets.

\begin{defi}
   \looseness=-1
   Let $N$ be a clause set, $\cst{p}$ be a predicate symbol,
   $G \subseteq N$ be a definition set
   for $\cst{p}$, and $R = \withpred{N}{\cst{p}}
   \setminus G$. \emph{Defined predicate elimination} (DPE) of $\cst{p}$ in $N$ replaces $N$ by
   $\withoutpred{N}{\cst{p}} \cup
%%% @PETAR: Double-check the supression of _p below. --JB
   (\confrep{\withpred{G}{\cst{p}}}{G} \flatres_{\!\cst{p}} \confrep{\withpred{R}{\cst{p}}}{R})$.
\end{defi}

\newcommand{\mm}{\ourmodel}
\newcommand{\notmodels}{\nvDash}
\begin{rep}
   \begin{lemma}
   \label{lem:unsat-fresh-consts}
   Let $N(\tupleempty{x})$ be a clause set such that the variables of all
   clauses in it are among the argument $n$-tuple $\tupleempty{x}$, and let
   $\tupleempty{\cst{c}}$ be an $n$-tuple of distinct fresh constants. If
   $N(\tupleempty{\cst{c}})$ {\upshape(}i.e.,
   $\substterm{\{\tupleempty{x}\mapsto\tupleempty{\cst{c}}\}}{N(\tupleempty{x})}${\upshape)} is
   unsatisfiable, then for every interpretation $\mm$ and valuation $\xi$,
   $\mm \notmodels_\xi N$.
   \end{lemma}
   \begin{proof}
      We show the contrapositive. Assume that for some $\mm$ and $\xi$,  $\mm \models_\xi N(\tupleempty{x})$.
      Then let $\ourmodel'$
      be a model that assigns each $\cst{c}_i$ the interpretation of $x_i$ under $\mm$ and $\xi$, and otherwise
      coincides with $\ourmodel$. We obtain $\ourmodel' \models N(\tupleempty{\cst{c}})$.
   \end{proof}

   \begin{lemma}
      \label{lem:flat-res-set-step-satisfiability}
      Let $G$ be a definition set for $\cst{p}$\confrep{,}{} and $N$ \confrep{}{be }an arbitrary clause
      set. If $(G, N) \flatresiter (G, N')$, then $G \cup N$ and $G \cup N'$ are
      equivalent.
   \end{lemma}
   \begin{proof}
      Since flat resolution is sound, the nontrivial direction is to show that a
      model $\mm$ of the set $G \cup N'$ is also a model of $G \cup N$. As the only clause in $N
      \setminus N'$ is $C = \arbpredlit{\cst{p}(\tuple{s}{n})} \cor C'$ on which
      the $\flatresiter$ step is performed, we must show $\mm \models C$.
      % Without 

      % Let $\mm$ be canonical model of $G \cup N'$ \cite[Theorem~9.5.2]{mf-1996-fol} and let $C
      % \in N \setminus N'$. We need to show that $\mm \models C$---which is to say,
      % for all variable interpretation $\xi$, we have $\mm \models_\xi C$. To
      % lighten notations, we will assume $C$ is ground and ignore $\xi$. Canonical
      % models make this step possible.

      % First, $C$ must have the form $\arbpredlit{\cst{p}(\tuple{s}{})} \cor C'$,
      % where $\tuple{s}{}$ is a tuple of ground terms. 
      Without loss of generality,
      we assume that the leading literal of $C$ is positive (i.e., $C$ is of the form $\pospredlit{\cst{p}(\tuple{s}{n})} \cor C'$).
      Towards a contradiction, assume $\xi$ is a valuation such that $\mm \notmodels_\xi C$. Then, $\mm \notmodels_\xi
      \pospredlit{\cst{p}(\tuple{s}{n})}$. 
      % Let $\xi'$ be a valuation that
      % assigns every instance $D = \pospredlit{\cst{p}(\tupleempty{s})} \cor D'$ of a clause in
      % $G$, since $\mm \notmodels \pospredlit{\cst{p}(\tuple{s}{})}$, we have $\mm
      % \models D'$.
      Consider an arbitrary clause $D = \pospredlit{\cst{p}}(\tuplen{x}) \cor D'
      \in \withpredpos{G}{\cst{p}}$ and a valuation $\xi'$, which assigns each $x_i$ the
      interpretation of $s_i$ under $\mm$ and $\xi$. As $\mm \notmodels_{\xi'}
      \pospredlit{\cst{p}}(\tuple{x}{n})$ and $\mm \models G$, then $\mm \models_{\xi'} D'$ for every
      such clause $D$.
   %
      However, by part 5 of Definition~\ref{def:definition} and by Lemma
      \ref{lem:unsat-fresh-consts}, $\mm \notmodels_{\xi'} E(\tuplen{x})$, where $E(\tuplen{x})$
      is the environment associated with the definition set $G$.
      Therefore, there must exist a clause $D =
      \negpredlit{\relax{\cst{p}(\tuplen{x})}} \cor D'$ in $\withpredneg{G}{\cst{p}}$ such
      that $\mm \notmodels_\xi D'$.


      Now consider the flat resolvent of $C$ and $D$ on~$\cst{p}$: $R =
      \neqlit{x_1}{s_1} \cor \cdots \cor \neqlit{x_n}{s_n} \cor C' \cor D'$.
      Let $\zeta$ be a valuation coinciding with $\xi$ on the variables of $C$
      and with $\xi'$ on $\tuplen{x}$.
      Clearly, $\mm \notmodels_\zeta R$. Yet, $R \in N'$, and as $\mm \models N'$, we reach a contradiction.
   \end{proof}

   \begin{lemma}
      \label{lem:flat-res-set-last-step-satisfiability}
      Let $G$ be a definition set for $\cst{p}$\confrep{,}{} and $N$ \confrep{}{be }a clause set with no occurrences of $\cst{p}$.
      Then $G \cup N$ is satisfiable if and only if $N$ is satisfiable.
   \end{lemma}
   \begin{proof}
      The nontrivial direction is to show that if $N$ is satisfiable, $G \cup N$ is as well.
      %
      Let $\mm$ be a model of $N$. We construct a model $\mm'$ of $G$ over
      the same universe as $\mm$. For any atom $A$ such that $\cst{p}$ does not
      occur in $A$ and for every $\xi$, we set $\mm' \models_\xi A$ if and only if
      $\mm \models_\xi A$. For any clause $\pospredlit{\cst{p}(\tuplen{x})} \cor
      C' \in G$ and any assignment $\xi$ such that $\mm \notmodels_\xi C'$, we
      define $\mm'$ so that $\mm'\models_\xi \cst{p}(\tuplen{x})$. By
      construction, $\mm' \models \withpredpos{G}{\cst{p}} \cup N$. It remains to show that $\mm' \models
      \withpredneg{G}{}$.

      Let $C = \negpredlit{\cst{p}(\tuplen{x})} \cor C' \in G$ and let $\xi$ be
      an arbitrary assignment. Towards a contradiction, assume
      $\mm'\notmodels_\xi C$, and consequently $\mm' \models_\xi
      \cst{p}(\tuplen{x})$. By construction of $\mm'$, there exists a clause
      $\pospredlit{\cst{p}(\tuplen{y})} \cor D' \in G$ and an assignment $\xi'$
      which assigns each $y_i$ the value of $\xi(x_i)$ such that $\mm
      \notmodels_{\xi'} D'$. The resolvent $R = \neqlit{x_1}{y_1} \lor \cdots \lor
      \neqlit{x_n}{y_n} \lor C' \lor D'$ is a tautology, according to condition
      4 of Definition \ref{def:definition}. However, for a valuation that
      behaves like $\xi$ on $\tupleempty{x}$ and $\xi'$ on $\tupleempty{y}$,
      $\mm'$ does not satisfy $R \in N$, contradicting our assumption.
      % @Jasmin: Your trick with var renaming does not work as flat resolvent is
      % defined on
      % variable-disjoint clauses.
   \qedhere
   \end{proof}
\end{rep}
\begin{conf}

\end{conf}
\begin{theorem}
\label{thm:pes-sat-equiv}
   The result of applying DPE to a clause set $N$ is
   satisfiable if and only if $N$ is satisfiable.
\end{theorem}
\begin{rep}
\begin{proof}
   Let $\cst{p}$ be a predicate symbol and $G \subseteq N$ be the
   definition set used by DPE, and let $R = \withpred{N}{\cst{p}} \setminus G$.
%
   % First, using Lemmas \ref{lem:flat-res-set-termination-confluence} and \ref{lem:flat-res-set-step-satisfiability}
   % we show that we will eventually obtain a set $R'$
   % that contains no occurrences of $\cst{p}$ and that preserves satisfiability
   % of the original $R$. Finally, we will show that we can
   % omit $G$ in the result without affecting satisfiability.

   Using Lemma
   \ref{lem:flat-res-set-termination-confluence}, we get that there is a
   derivation $(G,R) \flatresiter^n (G,R') \flatresiter R'$. Applying Lemma
   \ref{lem:flat-res-set-step-satisfiability} $n$ times, we get that $G \cup R$
   is equivalent to $G \cup R'$. Finally, Lemma \ref{lem:flat-res-set-last-step-satisfiability}
   gives us the desired result.
\end{proof}
\end{rep}

Since there will typically be at most only a few defined predicates in the
problem, it makes sense to fall back on SPE when no definition is found.

\begin{defi}
   \looseness=-1
   Let $N$ be a clause set and $\cst{p}$ be a predicate symbol. If there exists a
   definition set $G \subseteq N$ for $\cst{p}$, \emph{portfolio predicate
   elimination} (PPE) on $\cst{p}$ in $N$ replaces $N$ with
%%% @PETAR: Double-check the supression of _p below. --JB
   $\withoutpred{N}{\cst{p}} \cup (\confrep{\withpred{G}{\cst{p}}}{G} \flatres_{\!\cst{p}}
   \confrep{\withpred{R}{\cst{p}}}{R})$, where $R = \withpred{N}{\cst{p}} \setminus G$.
   Otherwise, if $\cst{p}$ is singular in $N$, it results in $\withoutpred{N}{\cst{p}}
   \cup (\withpredpos{N}{\cst{p}} \flatres_{\!\cst{p}} \withpredneg{N}{\cst{p}})$.
   In all other cases, it is not applicable.
\end{defi}

\subsection{Refutational Completeness}
\label{ssec:predicate-elimination-refutational-completeness}

\newcommand\FInf{\mathit{FInf}}
\newcommand\FLInf{\mathit{FLInf}}
\newcommand\Red{\mathit{Red}}
\newcommand\RedI{\Red_\mathrm{I}}
\newcommand\RedF{\Red_\mathrm{F}}
\newcommand\LRed{\mathit{LRed}}
\newcommand\LRedI{\LRed_\mathrm{I}}
\newcommand\LRedF{\LRed_\mathrm{F}}
\newcommand\gnd{\mathcalx{G}}
\newcommand\pow[1]{\mathcalx{pe}(#1)}
\newcommand\Lab{\mathbf{L}}
\newcommand\FFLab{{\mathbf{FL}}}
\newcommand\Inv{\mathit{Inv}}

\newcommand\RedWk{\smash{\Red\Wksup}}
\newcommand\RedIWk{\smash{\Red_\mathrm{I}\Wksup}}
\newcommand\RedFWk{\smash{\Red_\mathrm{F}\Wksup}}

\newcommand\Wksym{\flat}
\newcommand\Wksup{^\Wksym}
\newcommand\modelsWk{\models\Wksup}
%\newcommand\modelsWkcapgnd{\models^{\Wksym{}\gnd}_\cap}
\newcommand\modelsWkcapgnd{\modelsWk}
\newcommand\LRedWk{\LRed^{\Wksym}}
\newcommand\LRedWksub{\LRed^{\Wksym,\sqsupset}}
\newcommand\LRedFWksub{\LRedF^{\Wksym,\sqsupset}}
\newcommand\LRedIWk{\LRedI^{\Wksym}}
\newcommand\Wk[1]{#1^\Wksym}
\newcommand\prop{o}
\newcommand\true{\top}
\newcommand\false{\bot}

\looseness=-1
Hidden-literal-based techniques fit within the traditional framework of
saturation, because they delete or reduce a clause based on the \emph{presence}
of other clauses. In contrast, predicate elimination relies on the
\emph{absence} of clauses from the proof state. We can still integrate it with
superposition as follows: At every $k$th iteration of the given clause
procedure, perform predicate elimination on $\mathcal{A}
\cup \mathcal{P}$, and add all new clauses to $\mathcal{P}$.

One may wonder whether such an approach preserves the refutational
completeness of the calculus. The answer is no.
%
\begin{conf}
To see why, consider the following \emph{binary splitting} rule
based on Riazanov and Voronkov \cite{riazanov-voronkov-2001}:
%
\[\namedsimp{BS}{C \cor D}{\cst{p} \cor C \quad D \cor \neglit{\cst{p}}}\]
%
Provisos: $C$ and $D$ have no free variables in common, $\cst{p}$ is fresh, and
$\cst{p}$ is $\prec$-smaller than $C$ and $D$. Since the conclusions are
smaller than the premise, the rule can be applied aggressively as a
simplification. But notice that the effect of splitting can be undone by
singular predicate elimination, possibly giving rise to loops
$\infname{BS}, \infname{SPE}, \infname{BS}, \infname{SPE}, \dotsc$.
This breaks completeness.

Our solution is to curtail the entailment relation used by the redundancy
criterion to disallow splitting-like simplifications. Weak entailment $\modelsWk$
is defined via an ad hoc nonclassical logic so that $\{\cst{p} \cor C{,}\;
\neglit{\cst{p}} \cor C\} \notmodelsWk \{C\}$ and yet $\modelsWk \{\cst{p} \cor
\neglit{\cst{p}}\}$.
%
More precisely, this logic is defined via an
encoding: $M \modelsWk N$ if and only if $\Wk{M} \models \Wk{N}$, where
%
$\Wk{\cst{p}(\tuple{t}{})} = \cst{p}(\tuple{t}{}) \noteq \false$,
$\Wk{\lnot\,\cst{p}(\tuple{t}{})} = \cst{p}(\tuple{t}{}) \noteq \true$, and
$\Wk{L} = L$ otherwise.
%
Moreover, the type $\prop$ may be interpreted as any set of cardinality at least
2, and $\false$ must be a distinguished symbol interpreted differently
from~$\top$.

The standard redundancy criterion $\RedWk$ based on $\modelsWk$ supports all the
familiar deletion and simplification techniques except splitting. Using $\RedWk$
not only prevents looping, but it also enables the use of
the given clause procedure, because any redundant inference
according to $\RedWk$ remains redundant after SPE or DPE. As usual, the devil is
in the details, and the details are in the report \cite{our-report}.
\end{conf}

\begin{rep}
To see why, consider the following \emph{binary splitting} rule
based on Riazanov and Vo\-ro\-nkov~\cite{riazanov-voronkov-2001}:
%
\[\namedsimp{BS}{C \cor D}{\cst{p} \cor C \quad D \cor \neglit{\cst{p}}}\]
%
Provisos: $C$ and $D$ have no free variables in common, $\cst{p}$ is fresh, and
$\cst{p}$ is $\prec$-smaller than $C$ and $D$. Since the conclusions are
smaller than the premise, the rule can be applied aggressively as a
simplification. But notice that the effect of splitting can be undone by
singular predicate elimination, possibly giving rise to loops
$\infname{BS}, \infname{SPE}, \infname{BS}, \infname{SPE}, \dotsc$.
Clearly, we need to curtail predicate elimination.

Under which conditions is predicate elimination refutationally complete? To
answer this question, we employ the saturation framework of Waldmann, Tourret,
Robillard, and Blanchette \cite{wtrb-20-sat-framework}. Let
$(\FInf, \Red)$ be the base calculus without predicate elimination---e.g.,
resolution or superposition inferences together with the standard
redundancy criterion \cite[Sect.~4.2]{bg-01-resolution}. The
inference system $\FInf$ is a set of inferences $(C_n,\ldots,C_1,C_0)$, for $n
\ge 1$, where $C_n,\ldots,C_1$ are the premises and $C_0$ is the conclusion.
$C_1$ is called the main premise. %; $C_n,\ldots,C_2$ are the side premises.
The redundancy criterion is a pair $\Red = (\RedI, \RedF)$ where $\RedI$
determines which inferences can be omitted and $\RedF$ is used to remove
clauses.

Next, consider an abstract proving process working on a single clause set.
Let $\rhd_{\Red}$ denote the transition relation that supports (1)~adding
arbitrary clauses and (2)~removing clauses deemed useless by $\RedF$.
Typically, the added clauses are the result of performing inferences and are
entailed by the premises, but other clauses can be added as well. A
\emph{$\rhd_{\Red}$-derivation} is a finite or infinite sequence of clause sets
$N_0 \rhd_{\Red} N_1 \rhd_{\Red} \cdots$.

We fix a finite set $\mathbf{P}$ of predicate symbols that may be subjected to
predicate elimination. These might include all the predicate symbols occurring
in the input problem, but exclude any symbols introduced by splitting or other
rules. Given a clause or clause set $N$, we write $\mathbf{P}(N)$ to denote the
set of all predicate symbols from $\mathbf{P}$ occurring in $N.$
%
Let $\rhd_\mathbf{P}$ denote the elimination of a
singular or defined predicate symbol from $\mathbf{P}$. A \emph{mixed
derivation} consists of transitions either of the form $N
\rhd_\mathbf{P} N'$ or of the form $N \rhd_{\Red} N'$ where
$\mathbf{P}(N) \supseteq \mathbf{P}(N')$.
Because $\mathbf{P}$ is finite, any mixed derivation consists of at most
finitely many $\rhd_\mathbf{P}$-transitions. Hence, in any derivation,
there exists an index~$k$ from which all transitions are standard
${\rhd}_{\Red}$-transitions.

This suggests the following path to completeness: Pretend that the transitions
between $N_0$ and $N_k$ are merely preprocessing and start the actual
derivation at $N_k$. This works at the abstract level of derivations on single
clause sets. It fails, however, for an actual saturation prover that
distinguishes between passive and active clauses.

\begin{exa}
\label{ex:cex-predelim-sat}
The counterexample below is based on the given clause prover \textsf{GC}
from the saturation framework. It shows how predicate elimination can break
\textsf{GC}'s key invariant, which states that all inferences between active
clauses are redundant. Breaking the invariant means that the limit might be
unsaturated, breaking the refutational completeness proof.

We use superposition with the order $\cst{a} \prec
\cst{b} \prec \cst{c} \prec \cst{d}$ and without selection.
Assume $\cst{a} \in \mathbf{P}$ and
suppose we start with the satisfiable clause set %consisting of
%
%\begin{linenomath*}
\begin{align*}
  & \neglit{\cst{a}} \cor \MAX{\cst{d}}
  && \neglit{\cst{a}} \cor \MAX{\neglit{\cst{d}}}
  && \cst{a} \cor \cst{b} \cor \MAX{\cst{c}}
  && \cst{c} \cor \MAX{\cst{d}}
  && \cst{b} \cor \MAX{\neglit{\cst{d}}}
\end{align*}
%\end{linenomath*}
%
where gray boxes mark maximal (i.e., eligible) literals. Suppose the prover makes
$\cst{c} \cor \cst{d}$ and $\cst{b} \cor \neglit{\cst{d}}$ active. From these
two clauses, a superposition inference~$\iota$ could derive the conclusion
$\cst{b} \cor \cst{c}$. However, the three passive clauses are
$\prec$-smaller than $\iota$'s main premise $\cst{b} \cor \neglit{\cst{d}}$ and
collectively entail $\iota$'s conclusion. This means that $\iota$ is
redundant and can be ignored.

If the prover now eliminates the predicate $\cst{a}$ using \infname{SPE}, the
passive set is reduced to $\{\cst{b} \cor \cst{c} \cor \cst{d}{,}\;
\cst{b} \cor \cst{c} \cor \neglit{\cst{d}}\}$.
%
Either clause is subsumed by an active clause, so the prover deletes it.
It stops with the active set
$\{\cst{c} \cor \cst{d}{,}\; \cst{b} \cor \neglit{\cst{d}}\}$, which is
unsaturated because $\iota$ is no longer redundant. The invariant is broken.
\end{exa}

\begin{exa}
\label{ex:cex-predelim-unsat}
In Example~\ref{ex:cex-predelim-sat}, the initial clause set was satisfiable.
If it is unsatisfiable, we can even lose refutational
completeness. To see why, we add the unit clauses
$\neglit{\cst{b}}$ and $\neglit{\cst{c}}$ to the initial clause set of
Example~\ref{ex:cex-predelim-sat} to make it unsatisfiable. We repeat the same
steps as above, including the subsumptions at the end,
yielding the passive set $\{\MAX{\neglit{\cst{b}}}, \MAX{\neglit{\cst{c}}}\}$ and
the active set $\{\cst{c} \cor \MAX{\cst{d}}{,}\; \cst{b} \cor \MAX{\neglit{\cst{d}}}\}$. Then,
making $\neglit{\cst{b}}$ and $\neglit{\cst{c}}$ active triggers no
inferences. The prover stops with an
unsatisfiable four-clause active set that does not contain the empty clause.
\end{exa}

A solution could be to move all active clauses to the passive set at step~$k$
or later, but this would be costly, since it would force the prover to redo
inferences whose conclusions might then have to be simplified or subsumed again.
Instead, we salvage the existing completeness proof for $\mathsf{GC}$, by
resolving the issues concerning splitting and the $\mathsf{GC}$ invariant. Our
approach is to weaken the redundancy criterion slightly, enough both to disable
splitting on $\mathbf{P}$-predicates and to ensure that
inferences such as $\iota$ in Examples
\ref{ex:cex-predelim-sat}~and~\ref{ex:cex-predelim-unsat} are performed. The
required weakening is so mild that it does not invalidate any practical
simplification or subsumption techniques we are aware of, except of course
splitting.

In accordance with the saturation framework, let $\mathbf{F}$ be the set of
first-order $\mupSigma$-clauses, let $\mathbf{G}$ be its ground subset,
and let $\gnd$ be a function that maps an $\mathbf{F}$-clause to the set of its
$\mathbf{G}$-clause instances and analogously for $\mathbf{F}$-inferences. We
define an extension $\mathbf{G}\Wksup$ of $\mathbf{G}$ for
$\mupSigma\Wksup$-clauses in an ad hoc nonclassical logic reminiscent
of paraconsistent logics \cite{carnielli-et-al-2007}. The objective is to
disallow the entailment that makes splitting and Examples
\ref{ex:cex-predelim-sat}~and~\ref{ex:cex-predelim-unsat} possible.
%
The signature~$\mupSigma\Wksup$ extends $\mupSigma$ with a
distinguished predicate symbol $\false$ that is interpreted differently
from~$\top$. For $\mupSigma\Wksup$, the Boolean type $\prop$ may be
interpreted as any set of cardinality at least 2.

\begin{defi}
The operator $\Wk{}$ translates $\mupSigma$-literals to
$\mupSigma\Wksup$-literals as follows, where $\cst{p} \in \mathbf{P}$,
$\cst{q} \notin \mathbf{P}$, and $s, t$ are non-Boolean terms:
\pagebreak[2]
%
%\begin{linenomath*}
\begin{align*}
  \Wk{\cst{p}(\tuple{t}{})} & = \cst{p}(\tuple{t}{}) \noteq \false
& \Wk{\cst{q}(\tuple{t}{})} & = \cst{q}(\tuple{t}{}) \eq \true
& \Wk{(s \eq t)} & = s \eq t \\[-\jot]
  \Wk{\lnot\,\cst{p}(\tuple{t}{})} & = \cst{p}(\tuple{t}{}) \noteq \true
& \Wk{\lnot\,\cst{q}(\tuple{t}{})} & = \cst{q}(\tuple{t}{}) \noteq \true
& \Wk{(s \noteq t)} & = s \noteq t
\end{align*}
%\end{linenomath*}
%
The operator is lifted elementwise to $\mathbf{G}$-clauses and
$\mathbf{G}$-clause sets.
The \emph{weak entailment} $\modelsWk$ over $\mathbf{G}$-clause sets
is defined via an encoding into $\mupSigma\Wksup$-clauses:
$M \modelsWk N$ if and only if $\Wk{M} \models \Wk{N}$.
The lifting to $\mathbf{F}$-clauses and $\mathbf{F}$-clause set is achieved
in the standard way via grounding.
\end{defi}

The following property of weak entailment will allow us to eliminate
$\mathbf{P}$-predicates without losing completeness:

\begin{lemma}
\label{lem:p-Wk-entail}
Let $C$ be a clause that contains the predicate symbol $\cst{p} \in
\mathbf{P}$ and $D$ be a clause that does not contain $\cst{p}$. If $N
\cup \{C\} \modelsWk \{D\}$, then $N \modelsWk \{D\}$.
\end{lemma}

\begin{proof}
Suppose $\mathscr{J} \models \Wk{N}$. We will define $\mathscr{J}'$ so that
$\mathscr{J}' \models \Wk{N} \cup \{\Wk{C}\}$, retrieve $\mathscr{J}'
\models \Wk{D}$, and then argue that $\mathscr{J} \models \Wk{D}$. We
take $\mathscr{J}'$ to coincide with $\mathscr{J}$ except that we extend the
domain for $\prop$ with one fresh value and use this value as the
interpretation of $\cst{p}(\tuple{t}{})$ for all argument tuples $\tuple{t}{}$.
This modification makes any $\cst{p}$ literal of $\Wk{C}$ true, and it
preserves the truth of $\Wk{N}$. By the hypothesis, $\mathscr{J}' \models
\Wk{D}$. And since $\cst{p}$ does not occur in $D$, we have $\mathscr{J}
\models \Wk{D}$.
\end{proof}

Note that the above lemma does not hold for classical entailment $\models$;
indeed, $\{\cst{p} \cor \cst{q}{,}\; \neglit{\cst{p}} \cor \cst{q}\} \models
\{\cst{q}\}$ yet $\{\cst{p} \cor \cst{q}\} \not\models
\{\cst{q}\}$. On the other hand, the law of excluded middle does hold for weak
entailment: $\modelsWk \cst{p} \cor \lnot\,\cst{p}$. In fact, all classical
clausal tautologies are tautologies for $\modelsWk$. 

The standard redundancy criterion $\Red$ is obtained by lifting a criterion on
$\mathbf{G}$-clauses to $\mathbf{F}$-clauses. The same construction can be
replicated using $\modelsWk$ instead of $\models$, yielding the \emph{weak
redundancy criterion} $\RedWk$.
It is easy to check that the usual simplification techniques implemented in
superposition provers can be justified using $\RedWk$. Specifically,
this concerns the following rules described by Schulz \cite[Sects.\
2.3.1~and~2.3.2]{ss-02-brainiac}:\
deletion of duplicated literals, 
deletion of resolved literals, 
syntactic tautology deletion,
semantic tautology deletion,
rewriting of negative literals,
positive simplify-reflect,
negative simplify-reflect,
clause subsumption, and
equality subsumption.
Moreover, rewriting of positive literals is possible if the
rewriting clause is smaller than the rewritten
clause (a condition that is also needed with $\models$ but omitted by Schulz
to allow more aggressive application of this useful rule).
Finally, destructive equality resolution cannot be justified with $\models$,
let alone $\modelsWk$.

We instantiate the saturation framework with $(\FInf,\RedWk)$ to obtain a
given clause prover \textsf{GC}. The prover operates on sets of labeled clauses
$(C, l)$, where $C$ is a standard clause and $l \in \Lab$ is a label.
The $\mathsf{active}$ label identifies active clauses; all other clauses are
passive. The prover takes the form of two rules,
\textsc{Process} and \textsc{Infer}, restricted to prevent the introduction of
$\mathbf{P}$-predicates. We extend it with a third rule,
\textsc{PredElim}, for predicate elimination, and call the extended prover
\textsf{GCP}. The rules are as follows, using again the framework notations:

\begin{description}[labelwidth=\widthof{\rm\textsc{PredElim}\,}]
\itemsep1\jot
\item[\rm\textsc{Process}\,]
  $\mathcalx{N} \cup \mathcalx{M}
   \,\Longrightarrow_\mathsf{GCP}\,
   \mathcalx{N} \cup \mathcalx{M}'$
\\
  where $\mathcalx{M} \subseteq \LRedFWksub(\mathcalx{N} \cup \mathcalx{M}')$,
  $\mathcalx{M}'{\downarrow}_\mathsf{active} = \emptyset$,
  and \\
  $\mathbf{P}(\lfloor\mathcalx{M}'\rfloor) \subseteq \mathbf{P}(\lfloor\mathcalx{N} \cup \mathcalx{M}\rfloor)$

\item[\rm\textsc{Infer}\,]
  $\mathcalx{N} \cup \{(C, l)\}
   \,\Longrightarrow_\mathsf{GCP}\,
   \mathcalx{N} \cup \{(C, \ensuremath{\mathsf{active}})\} \cup \mathcalx{M}$
\\
  where $l \not= \ensuremath{\mathsf{active}}$,
  $\mathcalx{M}{\downarrow}_\mathsf{active} = \emptyset$, \\
  $\FInf(\lfloor\mathcalx{N}{\downarrow}_\mathsf{active}\rfloor, \{C\}) \subseteq
    \RedIWk^{{\cap}\gnd}(\lfloor\mathcalx{N}\rfloor \cup \{C\} \cup \lfloor\mathcalx{M}\rfloor)$,
  and \\
  $\mathbf{P}(\lfloor\mathcalx{M}\rfloor) \subseteq \mathbf{P}(\lfloor\mathcalx{N}\rfloor \cup \{C\})$

\item[\rm\textsc{PredElim}\,]
  $\mathcalx{N} \cup \mathcalx{M}
   \,\Longrightarrow_\mathsf{GCP}\,
   \mathcalx{N} \cup \mathcalx{M}'$
\\
  where $\mathcalx{N} \cup \mathcalx{M} \rhd_\mathbf{P} \mathcalx{N} \cup \mathcalx{M}'$
  and $\mathcalx{M}'{\downarrow}_\mathsf{active} = \emptyset$
\end{description}

Here is a summary of the main framework notations:
%
\begin{itemize}
\item The letters $\mathcalx{M}, \mathcalx{N}$ range over sets of labeled clauses.
  $\mathcalx{M}{\downarrow}_l$ denotes the subset of clauses in $\mathcalx{M}$
  labeled with $l$. The operator $\lfloor\phantom{\cdot}\rfloor$ erases all
  labels in a labeled clause or clause set.

\smallskip

\item $\FInf(N)$ denotes the set of all base calculus inferences with premises
  in $N$, and $\FInf(N, M) = \FInf(N \cup M) \setminus \FInf(N \setminus M)$.
  The same notations are also available for the straightforward extension $\FLInf$
  of $\FInf$ with labels.

\smallskip

\item $\LRedWksub$ is the extension of the standard redundancy
  criterion $\RedWk$ defined using $\modelsWk$ to nonground labeled clauses
  with subsumption ($\sqsubset$).

\smallskip

\item Given a sequence $(\mathcalx{N}{}_i)_i$, its \emph{limit} (\emph{inferior})
  is $\mathcalx{N}{}_\infty = \bigcup_i \bigcap_{j\ge i} \mathcalx{N}{}_j$.
\end{itemize}

\begin{sloppypar}
   The completeness proof follows the invariance-based argument found in the
   article by Waldmann et al. \cite{waldmann-et-al-202x-article} about the saturation framework.
\end{sloppypar}

\begin{lemma}
\label{lem:gcp-derivations-are-red-black-derivations}
Every $\Longrightarrow_\mathsf{GCP}$-derivation is a mixed derivation.
\end{lemma}

\begin{proof}
   The cases for \textsc{Process} and \textsc{Infer} are almost as in Waldmann et
al., with adjustments to show that $\cst{P}$-predicates cannot appear from
nowhere. The case for \textsc{ElimPred} is trivial.
\end{proof}

Let $\Inv\Wksup_\mathcalx{N}(k)$ denote the condition
$\textstyle\FLInf(\mathcalx{N}{}_k{\downarrow}_\mathsf{active}) \subseteq
\LRedIWk(\mathcalx{N}{}_k)$. \vspace{0.5em}
Notice the difference with the definition of the key invariant
$\Inv_\mathcalx{N}$ in the saturation framework, whose right-hand side is
$\bigcup_{i=0}^k \RedI^{\Lab}(\mathcalx{N}{}_i)$. We cannot use the
big union ${\bigcup}$ starting at $i = 0$ because we will need to truncate a
sequence prefix of an a priori unknown length. The argument will still work
thanks to monotonicity properties of the redundancy criteria.

\begin{lemma}
\label{lem:gcp-invar-gcp}
Let $(\mathcalx{N}{}_i)_i$ be a $\Longrightarrow_\mathsf{GCP}$-derivation.
If
$\mathcalx{N}{}_0{\downarrow}_\mathsf{active} = \emptyset$,
then
$\Inv\Wksup_\mathcalx{N}(k)$ holds for all indices~$k$.
\end{lemma}

\begin{proof}
The base case is as in Waldmann et al.

For \textsc{Process} and \textsc{Infer}, the proof is essentially as in Waldmann
et al., except that we also need to show that
$\LRedIWk(\mathcalx{N}{}_k) \subseteq \LRedIWk(\mathcalx{N}{}_{k+1})$.
This is a consequence of
$\mathcalx{N}{}_k \rhd_{\LRedWksub} \mathcalx{N}{}_{k+1}$ and of
properties (R2) and (R3) of redundancy criteria.

\begin{sloppypar}
   
   A new case to consider is that of a \textsc{PredElim} transition
   $\mathcalx{N}{}_{k} \Longrightarrow_\mathsf{GCP} \mathcalx{N}{}_{k+1}$.
   Let $\mathcalx{N}{}_{k} = \mathcalx{N} \cup \mathcalx{M}
   \Longrightarrow_\mathsf{GCP} \mathcalx{N} \cup \mathcalx{M}' = \mathcalx{N}{}_{k+1}$,
   where $\mathcalx{N} \cup \mathcalx{M} \rhd_\mathbf{P}
   \mathcalx{N} \cap \mathcalx{M}'$ and
   $\mathcalx{M}'{\downarrow}_\mathsf{active} = \emptyset$.
   We assume without loss of generality that $\mathcalx{M} \cap \mathcalx{M}' =
   \emptyset$.
   Let $\cst{p}$ be the eliminated predicate. Note that $\cst{p}$ occurs in every
   clause in $\mathcalx{M}$ but in none of the clauses in $\mathcalx{N}$ or
   $\mathcalx{M}'$.
   We must show $\FLInf(\mathcalx{N}{}_{k+1} {\downarrow}_\mathsf{active})
   \subseteq \LRedIWk(\mathcalx{N}{}_{k+1})$.
   As for \textsc{Process}, we have the inclusion
   $\FLInf(\mathcalx{N}{}_{k+1} {\downarrow}_\mathsf{active})
   \subseteq \FLInf(\mathcalx{N}{}_k {\downarrow}_\mathsf{active})$,
   by the side condition that
   $\mathcalx{M}'{\downarrow}_\mathsf{active} = \emptyset$.
   Moreover, by the induction hypothesis,
   $\FLInf(\mathcalx{N}{}_k {\downarrow}_\mathsf{active})
   \subseteq \LRedIWk(\mathcalx{N}{}_k)$. Thus,
   $\FLInf(\mathcalx{N}{}_k {\downarrow}_\mathsf{active})
   \subseteq \LRedIWk(\mathcalx{N} \cup \mathcalx{M})$.
\end{sloppypar}

Let $\iota \in \FLInf(\mathcalx{N} {\downarrow}_\mathsf{active})$.
By the argument above, we have
$\iota \in \LRedIWk(\mathcalx{N} \cup \mathcalx{M})$.
We must
show $\iota \in \LRedIWk(\mathcalx{N} \cup \mathcalx{M}')$.
%
By definition of $\LRedIWk$, it suffices to show that for
every ground instance $(C_n,\ldots,C_1,C_0)$ of $\iota$, there exists a finite
clause set $\mathcalx{D} \subseteq \gnd(\mathcalx{N}) \cup \gnd(\mathcalx{M}')$
that is $\prec$-smaller than $C_1$ and such that
$\{C_n,\ldots,C_2\} \cup \mathcalx{D} \modelsWk \{C_0\}$.
Without loss of generality, we assume that $\mathcalx{D}$ is the $\prec$-smallest such set; such a set exists because $\prec$ is well founded.

By definition of $\mathcalx{N}$, $\cst{p}$ cannot occur in $C_0$.
By Lemma~\ref{lem:p-Wk-entail}, if $\cst{p}$ occurred in $D \in \mathcalx{D}$,
we could remove $D$, but this would mean $\mathcalx{D}$ is not minimal.
As a result, $\mathcalx{D}$ cannot contain clauses from $\gnd(\mathcalx{M})$ and
hence $\mathcalx{D} \subseteq \gnd(\mathcalx{N})$. Thus,
$\iota \in \LRedIWk(\mathcalx{N})$. By property (R2) of
redundancy criteria, we have the desired result: $\iota \in
\LRedIWk(\mathcalx{N} \cup \mathcalx{M}')$.
\end{proof}

\begin{lemma}
\label{lem:gcp-invar-infinity}
Let $(\mathcalx{N}{}_i)_i$ be a
$\rhd_{\LRedWksub}$-derivation.
If $\Inv\Wksup_\mathcalx{N}(i)$ holds for all indices~$i$, then
$\FLInf(\mathcalx{N}{}_\infty{\downarrow}_\mathsf{active}) \subseteq
\bigcup_i \LRedIWk(\mathcalx{N}{}_i)$
holds.
\end{lemma}

\begin{proof}
We assume $\iota \in \FLInf(\mathcalx{N}{}_\infty {\downarrow}_\mathsf{active})$
and show $\iota \in \bigcup_i \LRedIWk(\mathcalx{N}{}_i)$
for some arbitrary $\iota$.
%
For $\iota$ to belong to $\FLInf(\mathcalx{N}{}_\infty {\downarrow}_\mathsf{active})$, all of
its finitely many premises must be in $\mathcalx{N}{}_\infty {\downarrow}_\mathsf{active}$.
Therefore, there must exist an index $k$ such that
$\mathcalx{N}{}_k {\downarrow}_\mathsf{active}$ contains all of them, and therefore
$\iota \in \FLInf(\mathcalx{N}{}_k {\downarrow}_\mathsf{active})$. Since $\Inv_\mathcalx{N}(k)$
holds, $\iota \in \LRedIWk(\mathcalx{N}{}_k)$.
Hence, $\iota \in \bigcup_i \LRedIWk(\mathcalx{N}{}_i)$.
\end{proof}

\begin{lemma}
\label{lem:fair-gcp-derivations}
Let $(\mathcalx{N}{}_i)_i$ be a $\Longrightarrow_\mathsf{GCP}$-derivation.
If
$\mathcalx{N}{}_0{\downarrow}_\mathsf{active} = \emptyset$
and
$\mathcalx{N}{}_\infty{\downarrow}_l = \emptyset$ for every label
$l \not= \ensuremath{\mathsf{active}}$,
then there exists an index $k$ such that
$(\mathcalx{N}{}_{k+i})_i$ is a fair $\rhd_{\LRedWksub}$-derivation.
\end{lemma}

\begin{sloppypar}
\begin{proof}
By Lemma~\ref{lem:gcp-derivations-are-red-black-derivations}, there must exist
an index $k$ such that the sequence $(\mathcalx{N}{}_{k+i})_i$ is a pure
$\rhd_{\LRedWksub}$-derivation.
By Lemma~\ref{lem:gcp-invar-gcp},
$\Inv\Wksup_\mathcalx{N}(k+i)$ holds for all indices~$i$.
Hence, by Lemma~\ref{lem:gcp-invar-infinity},
$\FLInf(\mathcalx{N}{}_\infty{\downarrow}_\mathsf{active}) \subseteq
\bigcup_{i} \LRedIWk(\mathcalx{N}{}_{k+i})$.
By the second hypothesis, this inclusion simplifies to
$\FLInf(\mathcalx{N}{}_\infty) \subseteq
\bigcup_{i} \LRedIWk(\mathcalx{N}{}_{k+i})$.
\end{proof}
\end{sloppypar}

\begin{theorem}
\label{thm:gcp-complete}
Let $(\mathcalx{N}{}_i)_i$ be a $\Longrightarrow_\mathsf{GCP}$-derivation
with
$\mathcalx{N}{}_0{\downarrow}_\mathsf{active} = \emptyset$
and
$\mathcalx{N}{}_\infty{\downarrow}_l = \emptyset$ for every label
$l \not= \ensuremath{\mathsf{active}}$.
If $\lfloor \mathcalx{N}{}_0\rfloor$ is unsatisfiable,
then
some $\mathcalx{N}{}_i$
contains the empty clause with some arbitrary label.
\end{theorem}

\begin{proof}
By Lemma~\ref{lem:fair-gcp-derivations},
we know that there exists an index $k$ such that
$(\mathcalx{N}{}_{k+i})_i$ is a fair $\rhd_{\LRedWksub}$-derivation.
Moreover, since
$\rhd_{\LRedWksub}$ and
$\rhd_\mathbf{P}$ preserve unsatisfiability
(by (R1) of redundancy criteria, Khasidashvili and Korovin's Theorem~1, and our
Theorem~\ref{thm:pes-sat-equiv}), we have that
$\lfloor \mathcalx{N}{}_k\rfloor$ is unsatisfiable.
Since the base calculus $(\FLInf,\allowbreak\LRed)$ is assumed to be statically
refutationally complete with respect to $\models$, the calculus
$(\FLInf,\allowbreak\LRedWk)$ with a weaker redundancy criterion is also
statically complete with respect to $\models$, and by the saturation framework,
$(\FLInf,\allowbreak\LRedWksub)$ preserves this. Exploiting the equivalence of
static and dynamic completeness (Lemmas 10~and~11
in Waldmann et al.~\cite{waldmann-et-al-202x-article}), we conclude that some $\mathcalx{N}{}_{k+i}$ must
contain a labeled empty clause.
\end{proof}
\end{rep}

\section{Satisfiability by Clause Elimination}
\label{sec:satfol:satisfiability-by-clause-elimination}

\looseness=-1
The main approaches to show satisfiability of a first-order problem are to
produce either a finite Herbrand model or a saturated clause set. Saturations
rarely occur except for very small problems or within decidable fragments. In
this section, we explore an alternative approach that establishes satisfiability
by iteratively removing clauses while preserving
%satisfiability and
unsatisfiability,
until the clause set has been transformed into the empty set. So
far, this technique has been studied only for QBF~\cite{hsb-14-QRAT}. We show that
\emph{blocked clause elimination} (BCE)
% for first-order logic
can be used for this purpose. It can efficiently solve some problems for which
the saturated set would be infinite. However, it can break the refutational
completeness of a saturation prover. We conclude with a procedure that
transforms a finite Herbrand model into a sequence of clause elimination steps
ending in the empty clause set, thereby demonstrating the theoretical power of
clause elimination.

Kiesl et al.\ \cite{ksstb-2017-blockedfol} generalized blocked clause
elimination to first-order logic. Their generalization uses flat
$L$-resolvents, an extension of flat resolvents that resolves a single
literal~$L$ against $m$~literals of the other clause.

\begin{defi}
   Let $C = L \cor C'$ and $D = L_1 \cor \cdots \cor L_m \cor D'$, where
   \begin{enumerate}
      \item $m \ge\nobreak 1$
      \item the literals $L_i$ are of opposite polarity to $L$
      \item $L$'s atom is $\cst{p}(\tuplen{s})$
      \item $L_i$'s atom is $\cst{p}(\tuple{t_i}{})$ for each~$i$
      \item $C$ and $D$ have no variables in common
   \end{enumerate}
   The clause
   $\bigl(\bigvee_{i=1}^m \bigvee_{j=1}^n
     \neqlit{s_j}{t_{ij}}\bigr) \cor C' \cor D'$
   is a \emph{flat $L$-resolvent} of $C$~and~$D$.
\end{defi}

\begin{defi}
   \label{def:equality-blocked}
   \begin{conf}%
      A clause $C = L \cor C'$ is (\emph{equality-})\emph{blocked} by $L$ in a clause
      set $N$ if all flat $L$-resolvents between $C$ and clauses in $N \setminus \{C\}$ are
      tautologies.
   \end{conf}%
   \begin{rep}%
      Let $C = L \cor C'$ be a clause and $N$ be a clause set.
      Let $N'$ consist of all clauses from $N \setminus \{C\}$ with their variables
      renamed so that they share no variables with $C$.
      The clause $C$ is (\emph{equality-})\emph{blocked} by $L$ in the set $N$ if
      all flat $L$-resolvents between $C$ and clauses in $N'$ are tautologies.
   \end{rep}
\end{defi}

Removing a blocked clause from a set preserves unsatisfiability
\cite{ksstb-2017-blockedfol}. Kiesl et al.\ evaluated the effect of removing all
blocked clauses as a preprocessing step and found that it increases
\confrep{}{the }prover's success rate.

In fact, there exist satisfiable problems that cannot be saturated in finitely
many steps regardless of the calculus's parameters but that can be reduced to
an empty, vacuously satisfiable problem through blocked clause elimination.

\begin{exa}
   \label{example:infinite-blocked-set}
   \looseness=-1
   Consider the clause set $N$ consisting of $C = \pospredlit{\cst{p}(x,x)}$ and
   $D = \negpredlit{\cst{p}(y_1,y_3)} \cor \pospredlit{\cst{p}(y_1,y_2)} \cor
   \pospredlit{\cst{p}(y_2,y_3)}$. Note that if no literal is selected, all
   literals can take part in superposition inferences (i.e., they are eligible), as literals in
   clause $D$ are $\succ$-uncomparable. In particular, the superposition of
   $\pospredlit{\cst{p}(x,x)}$ into $D$'s negative literal eventually needs to
   be performed regardless of the chosen selection function or term order, with
   the conclusion $E_1 = \pospredlit{\cst{p}(z_1,z_2)} \cor
   \pospredlit{\cst{p}(z_2,z_1)}$. Then, superposition of $E_1$ into $D$ yields
   $E_2 = \pospredlit{\cst{p}(z_1,z_2)} \cor \pospredlit{\cst{p}(z_2,z_3)} \cor
   \pospredlit{\cst{p}(z_3,z_1)}$. Repeating this process yields infinitely many
   clauses $E_i = \pospredlit{\cst{p}(z_1,z_2)} \cor \cdots \cor
   \pospredlit{\cst{p}(z_i,z_{i+1})} \cor \pospredlit{\cst{p}(z_{i+1},z_1)}$
   that cannot be eliminated using standard redu\-ndancy-based techniques.
\end{exa}

\looseness=-1
In the example above, the clause $D$ is blocked by its second or third
literal. If we delete $D$, $C$ becomes blocked in turn. Deleting
$C$ leaves us with the empty set, which is vacuously satisfiable. The example
suggests that using BCE during saturation might help focus the proof search.
Indeed, Kiesl et al.\ ended their investigations by asking whether BCE can be
used as an inprocessing technique in a saturation prover. Unfortunately,
in general the answer is no\confrep{.}{:}

\begin{exa}
   \label{example:bce-completeness}
   Consider the unsatisfiable set $N=\{ C_1, \ldots,\allowbreak C_6 \}$, where
%   \begin{linenomath*}
   \begin{align*}
      C_1 &= \negpredlit{\cst{c}} \cor \pospredlit{\cst{e}} \cor \MAX{\negpredlit{\cst{a}}} 
      & C_2 &= \negpredlit{\cst{c}} \cor \MAX{\negpredlit{\cst{e}}}
      & C_3 &= \pospredlit{\cst{b}} \cor \MAX{\pospredlit{\cst{c}}}
      \\
      C_4 &= \negpredlit{\cst{b}} \cor \MAX{\negpredlit{\cst{c}}}
      & C_5 &= \pospredlit{\cst{a}} \cor \MAX{\pospredlit{\cst{b}}} 
      & C_6 &= \pospredlit{\cst{c}} \cor \MAX{\negpredlit{\cst{b}}} 
         &
   \end{align*}
%   \end{linenomath*}
   Assume the simplification ordering $\cst{a} \prec \cst{b} \prec \cst{c} \prec
   \cst{d} \prec \cst{e}$ and the selection function that chooses the last negative literal of a clause as
   presented. Gray boxes indicate literals that can take part in superposition
   inferences. Only two superposition inferences are
   possible:\ from $C_3$ into $C_4$, yielding the tautology $C_{7} = \pospredlit{\cst{b}} \cor
   \MAX{\negpredlit{\cst{b}}}$, and from $C_5$ into $C_6$, yielding $C_{8} = \pospredlit{\cst{a}} \cor
   \MAX{\pospredlit{\cst{c}}}$. Clause $C_{7}$ is
   clearly redundant, whereas $C_{8}$ is blocked by its first literal. If we
   allow removing blocked clauses, the prover enters a loop: $C_{8}$ is repeatedly generated and 
   deleted. Thus, the prover will never generate the
   empty clause for this unsatisfiable set.
\end{exa}

   \newcommand{\aset}{\mathcal{A}}
   \newcommand{\pset}{\mathcal{P}}
   As with hidden tautologies, removing blocked clauses breaks the invariant of
   the given clause procedure that all inferences between clauses in $\aset$ are
   redundant. To see this, assume the setting of Example
   \ref{example:bce-completeness}, and let $\pset = N$ and $\aset = \emptyset$.
   Assume $C_1, C_2, C_3$ are moved to the active set. As there are
   no possible inferences between them, the proof state becomes $\aset = \{C_1,
   C_2, C_3\}$ and $\pset = \{C_4,C_5,C_6\}$. After $C_4$ is moved to
   $\aset$, the conclusion $C_7$ is computed, but it is not added to $\pset$ as it
   is redundant. Moving $C_5$ to $\aset$ produces no new conclusions, but after
   $C_6$ is moved, $C_{8}$ is produced. However, if we allow eliminating blocked
   clauses, it will not be added to $\pset$ as it is blocked. The prover then
   terminates with $\aset=N$ and $\pset=\emptyset$, even though the original set
   $N$ is unsatisfiable.

Although using BCE as inprocessing breaks the completeness of superposition in
general, it is conceivable that a well-behaved fragment of BCE might exist.
This could be investigated further.

   
Not only can BCE prevent infinite saturation (Example \ref{example:infinite-blocked-set}),
but it can also be used to convert a finite Herbrand model
into a certificate of clause set satisfiability (i.e., an object that carries the checkable proof of satisfiability). The certificate uses only
blocked clause elimination and addition, in conjunction with a transformation
to reduce the clause set to an empty set. This theoretical result
explores the relationship between Herbrand models and satisfiability certificates
based on clause elimination and addition. It is conceivable that it can form
the basis of an efficient way to certify Herbrand models.


In propositional logic, \emph{asymmetric literals} can be added to
or removed from clauses, retaining the equivalence of the resulting clause set with
the original one. Kiesl and Suda~\cite{ks-2017-unif-principle} described an extension of
this technique to first-order logic.
Their definition of asymmetric literals can be relaxed to
allow the addition of more literals, but the resulting set is then only
equisatisfiable to the original one, not equivalent.
This in turn allows us to show that a problem is satisfiable by
reducing it to an empty problem, as is done in some SAT solvers.

For the rest of this section, we work with clausal first-order logic
\relax{without equality}. We use \relax{Herbrand models} as canonical
representatives of first-order models, recalling that every
satisfiable set has a Herbrand model \cite[Sect.~5.4]{mf-1996-fol}.

\begin{defi}
   \looseness=-1
   A literal $L$ is a \emph{global asymmetric literal} (GAL) for a clause $C$
   and a clause set $N$ if for every ground instance $\sigmacl{C}$ of $C$, there
   exists a ground instance $\substterm{\varrho}{D} \cor \substterm{\varrho}{L'}$ of $D \cor L' \in N \setminus \{C\}$ such that $\substterm{\varrho}{D}
   \subseteq \substterm{\sigma}{C}$ and $\substterm{\varrho}{\neglit L'} = \sigmaterm{L}$.
 \end{defi}
\confrep{}{}

Every asymmetric literal is GAL, but the converse does not hold:

\begin{exa}
   \looseness=-1
   Consider a clause $C = \pospredlit{\cst{p}(x,y)}$ and a clause set $N = \{\pospredlit{\cst{q}} \cor
  \pospredlit{\cst{p}(\cst{a},\cst{a})}\}$. Then, $\negpredlit{\cst{q}}$ is not an asymmetric literal
  for $C$ and $N$, but it is a GAL for $C$ and $N$.
\end{exa}

Adding and removing GALs preserves and reflects satisfiability:

\begin{theorem}
   \label{thm:gal}
   If $L$ is a GAL for the clause $C$ and the clause set $N$, then the set $(N \setminus
   \{C\}) \cup\allowbreak \{ C \cor\nobreak L \}$ is satisfiable if and only if $N$ is satisfiable.
\end{theorem}
\begin{rep}%
\begin{proof}
   \looseness=-1
   Let $N' = N \setminus \{C\} \cup \{ C \cor L \}$.
   The nontrivial direction is to prove that if $N'$ has a model, so does
   $N.$ If $N'$ has a model, it has an Herbrand model $\ourmodel$. Clearly,
   $\ourmodel$ satisfies every clause in $N$, with the possible exception of
   $C$. Assume that there exists a grounding substitution $\sigma$ such that ground instance $\sigmaterm{C}$ is falsified by
   $\ourmodel$. Since $L$ is a GAL for $C$ and $N$, then there exists a clause $D \cor L' \in N'$, and a grounding substitution $\tau$ such that
   $\substcl{\tau}{D} \subseteq \sigmacl{C}$ and $\substcl{\tau}{\neg L'} =
   \sigmaterm{L}$. If $\ourmodel \models
   \substterm{\tau}{L'}$, for $\sigmaterm{C} \cor \sigmaterm{L}$ to be satisfied by $\ourmodel$ (as $C \cor L \in N'$), some
   literal in $\sigmaterm{C}$ must be satisfied by $\ourmodel$, contradicting that
   $\sigmaterm{C}$ is falsified by $\ourmodel$. If $\ourmodel \notmodels \substterm{\tau}{L'}$,
   then some literal in $\substterm{\tau}{D}$ must be satisfied. Since $\substterm{\tau}{D} \subseteq \sigmaterm{C}$,
   we get the same contradiction. Therefore, $\ourmodel$ satisfies $N$,
   as needed.
 \end{proof}

\end{rep}
\looseness=-1
For first-order logic without equality, a clause $L \cor C$ is blocked if all its
$L$-resolvents are tautologies \cite{ksstb-2017-blockedfol}. The $L$-resolvent
between $L \cor C$ and $\neglit{L_1} \cor \cdots \cor \neglit{L_n} \cor
D$ (renamed apart) is $\sigmacl{C \cor D}$, where $\sigma$ is the MGU
of the literals $L, L_1, \ldots, L_n$.
Given a Herbrand model $\ourmodel$ of a clause set $N$, the following procedure
removes all clauses while preserving satisfiability:

\begin{enumerate}
   \item \label{item:step1}
   \looseness=-1
   Let $\cst{q}$ be a fresh predicate symbol. For each atom
   $\cst{p}(\tupleempty{s})$ in the Herbrand universe: If
   $\ourmodel \models \cst{p}(\tupleempty{s})$, add the clause $\cst{q} \cor
   \cst{p}(\tupleempty{s})$; otherwise, add %the clause
   $\cst{q} \cor \neglit{\cst{p}(\tupleempty{s})}$. Adding either clause
   preserves satisfiability as both are blocked by~$\cst{q}$.
% \pagebreak[2]
   \smallskip
   \item \label{item:step2}
   Since $\ourmodel$ is a model, for each ground instance $\sigmacl{C}$, there exists a clause
   $\cst{q} \cor L$ with $L \in \sigmacl{C}$. We can transform $C \in N$ into
   $C \cor \neglit{\cst{q}}$, since $\neglit{\cst{q}}$ is a GAL for $C$ and $N$.

   \smallskip
   \item \label{item:step3}
   \looseness=-1
   Consider the clause $\cst{q} \cor L$ added by step \ref{item:step1}. Since
   $L$ is ground and no clause $\cst{q} \cor \neglit{L}$ was added (since $\ourmodel$ is a
   model), the only $L$-resolvents are against clauses added by step~\ref{item:step2}.
   Since all of those clauses contain $\neglit{\cst{q}}$, the resolvents are tautologies. 
   Thus, each $\cst{q} \cor L$ is blocked and can be removed in turn.

   \smallskip
   \item The remaining clauses all contain the literal $\neglit{\cst{q}}$. They can be removed
   by BCE as well.
\end{enumerate}


The procedure is limited to first-order logic without equality, since step
\ref{item:step3} is justified only if $L$ is a predicate literal. (Otherwise,
$L$ cannot block clause $\cst{q} \cor L$ \cite{ksstb-2017-blockedfol}.) The
procedure also terminates only for finite Herbrand models. 

% \begin{rep}

\begin{exa}
   Consider the satisfiable clause set $N = \{\pospredlit{\cst{r}(x)} \cor
   \pospredlit{\cst{s}(x)}{,}\; \negpredlit{\cst{r}(\cst{a})}{,}\allowbreak\;
   \negpredlit{\cst{s}(\cst{b})}\}$ and a Herbrand model $\ourmodel$ over
   $\{\cst{a}, \cst{b}, \cst{r}, \cst{s}\}$ such that
   $\cst{r}(\cst{b})$ and $\cst{s}(\cst{a})$ are the only true atoms in
   $\ourmodel$. We show how to remove all clauses in $N$ using $\ourmodel$ 
   by following the procedure above.

   Let $N_{\ourmodel} = \{ \cst{q} \cor \negpredlit{\cst{r}(\cst{a})}{,}\; \cst{q}
   \cor \pospredlit{\cst{r}(\cst{b})}{,}\; \cst{q} \cor
   \pospredlit{\cst{s}(\cst{a})}{,}\; \cst{q} \cor \negpredlit{\cst{s}(\cst{b})}
   \}$. We set $N \gets N \cup N_{\ourmodel}$. This preserves satisfiability
   since all clauses in $N_{\ourmodel}$ are blocked. It is easy to check that
   $\negpredlit{\cst{q}}$ is GAL for every clause in $N \setminus N_{\ourmodel}$. The
   only substitutions that need to be considered are $\{x \mapsto \cst{a} \}$ and $\{x \mapsto
   \cst{b} \}$ for $\pospredlit{\cst{r}(x)} \cor \pospredlit{\cst{s}(x)}$.
   So we set $N \gets \{\negpredlit{\cst{q}} \cor \pospredlit{\cst{r}(x)} \cor \pospredlit{\cst{s}(x)}{,}\;
   \negpredlit{\cst{q}} \cor \negpredlit{\cst{r}(\cst{a})}{,}\;
   \negpredlit{\cst{q}} \cor \negpredlit{\cst{s}(\cst{b})}\} \cup N_{\ourmodel}$.
   Clearly, all clauses in $N_{\ourmodel}$ are blocked, so we set $N \gets N \setminus
   N_{\ourmodel}$. All clauses remaining in $N$ have a literal $\negpredlit{\cst{q}}$
   and can be removed, leaving $N$ empty as desired.
\end{exa}

\section{Implementation}
\label{sec:satfol:implementation}
% {\large\bf {TODO: Shorten and introduce SPPE here in a sentence}}

\newcommand{\impmap}{\textit{Imp}}

Hidden-literal-based elimination, predicate elimination, \begin{qle}quasipure
elimination, \end{qle}and blocked clause
elimination all admit efficient implementations in a superposition
prover. In this section, we describe how to implement the first
\begin{noqle}two\end{noqle}\begin{qle}three\end{qle} sets of
techniques. For BCE, we refer to Kiesl et al.\ \cite{ksstb-2017-blockedfol}.
All techniques have been implemented in the Zipperposition prover.

\ourpara{Hidden-Literal-Based Elimination}
% 
% Heule et al.\ \cite{hjb-2010-cl-elim} show how hidden tautologies can be removed
% without creating the binary implication graph. For each literal~$L$ occurring in
% the clause set $N$, they compute the set $\PHL(L,N)$. Then for each $\neglit{L}'
% \in \PHL(L,N)$, they label $L'$ with $L$. A clause $C$ is a hidden tautology if
% there are two literals $L,L' \in C$ such that $L'$ is labeled with $L$. The
% described approach can be generalized to first-order logic and used to implement
% all rules from Sect.~\ref{sec:satfol:hidden-literal-based-elimination}.
% 
For HLBE, an efficient representation of $\HL(L,N)$ is crucial. Because
this set may be infinite, we underapproximate it by
restricting the length of the
transitive chains via a parameter $K_\mathrm{len}$. Given the current
clause set $N$, the finite map $\impmap[L']$ associates with each literal $L'$
a set of pairs $(L,M)$ such that $L' \bigfimpl{N}^k L$, where $k \leq
K_\mathrm{len}$ and $M$ is the multiset of clauses used to derive $L' \bigfimpl{N}^k L$.
Moreover, we consider only transitions of type 1 (as per
Definition~\ref{def:hl-fo}).
%Intuitively,
%$\impmap[L']$ contains all literals which can be reached from $L'$ following $k$
%edges of the generalized binary implication graph.
The following algorithm
maintains $\impmap$ dynamically, updating it as the prover derives and deletes
clauses.
It depends on the global variable $\impmap$ and the parameters
$K_\mathrm{len}$ and $K_{\mathrm{imp}}$.

% By choosing a limit $K_\mathrm{len}$ we can create a map $\impmap[L]$, which maps a literal $L$
% to a finite a set of pairs $(L', M)$ such that
% $\impk{L}{L'}{i}{M}$ where $i \leq K_\mathrm{len}$. It is important to record clauses used
% in deriving the implication, as this information is necessary to construct the
% proof. Mapping $\impmap$ is constructed so that whenever $(L', M) \in
% \impmap[L]$, then $L \in \HL(L',M)$.
% Proof by very simple induction

\looseness=-1

\algrenewcommand\alglinenumber[1]{{\color{gray} \footnotesize #1}}
\algrenewcommand\algorithmicindent{0.75em}

%%% TYPESETTING: hack
% \vskip\abovedisplayskip
% \kern-.5\jot

%% \begin{nolinenumbers}%\begin{figure}[h!]
\begin{algorithmic}[5]

%   \Procedure{DecomposeNegLit}{$c$, $C$}
%   \State $\vn{res} \gets \{(c, C)\}$
%   \ForAll{non-empty contexts $u$ such that $c = \neqlit{u[s]}{u[t]}$}
%       \State $\vn{res} \gets \{ (\neqlit{s}{t}, C) \} \cup \vn{res}$
%   \EndFor
%   \State \Return $\vn{res}$
%   \EndProcedure

%  \kern1\jot

  \Procedure{AddImplication}{$L_\mathrm{a}{,}\> L_\mathrm{c}{,}\> C$}
    \If{$\impmap[\sigmaterm{L_\mathrm{a}}] \not = \emptyset$ for some renaming $\sigma$} \label{statement:alpha}
      \State $(L_\mathrm{a}, L_\mathrm{c}) \gets (\sigmaterm{L_\mathrm{a}}, \sigmaterm{L_\mathrm{c}})$
    \EndIf

   %  \vspace{0.1em}
    \If{there are no $L,L',M,\sigma$ such that $(L',M) \in \impmap[L]$,\label{statement:more-general}
      %   \\\noindent\kern3.5ex 
        $\sigmaterm{L} = L_\mathrm{a}$, and $\sigmaterm{L'}=L_\mathrm{c}$} 
      % \State $\vn{Inst} \gets \{(\sigma, M) \mid (L_\mathrm{c}\sigma, M) \in \impmap[L_\mathrm{a}\sigma]\}$
      \ForAll{$(\sigma, M)$ such that $(\sigmaterm{L_\mathrm{c}}, M) \in \impmap[\sigmaterm{L_\mathrm{a}}]$} \label{statement:instances}
        \State {erase all $(L',M')$ such that $M \subseteq M'$ from $\impmap[\sigmaterm{L_{\mathrm{a}}}]$}
      \EndFor
      
      \ForAll{$L$ such that $(L', M) \in \impmap[L]$ and $\sigmaterm{L_\mathrm{a}} = L'$ for some $\sigma$} \label{statement:transitivity}
        \If{$|M| < K_\mathrm{len}$}
          \State $\impmap[L] \gets \impmap[L] \cup \{(\sigmaterm{L_\mathrm{c}}, M \uplus \{C\})\} $
        \EndIf
      \EndFor

      \ForAll{$L$ such that $\impmap[L] \not= \emptyset$ and $\sigmaterm{L} = L_\mathrm{c}$ for some $\sigma$} \label{statement:triggered}
         % \If{$|M| < K_\mathrm{len}-1$}
         \State $\vn{Concl} \gets \{(\sigmaterm{L'}, M \uplus \{\mathit{C}\}) \mid (L',M) \in \impmap[L], |M| < K_\mathrm{len}  \}$
         \State $\impmap[L_\mathrm{a}] \gets \impmap[L_\mathrm{a}] \cup  \vn{Concl}$
         % (L'\sigma, M \cup \{\mathit{C}\}) $
         % \EndIf
      \EndFor
      
      \State $\vn{Congr} \gets \{
         (\neqlit{s}{t}, \{C\}) \mid \exists u.\, L_\mathrm{c} = \neqlit{u[s]}{u[t]}
         \}$
      \State $\impmap[L_\mathrm{a}] \gets \impmap[L_\mathrm{a}] \cup \{ (L_\mathrm{c},\{C\}) \} \cup \vn{Congr}$ \label{statement:decomposition}

    \EndIf

  \EndProcedure

  \kern1\jot
%   \pagebreak[2]
   \newpage
 
  \Procedure{TrackClause}{$C$}
    \If{$C$ = $L_1 \cor L_2$}
      \State \textsc{AddImplication}($\neglit{L_1}$, $L_2$, $C$)
      \State \textsc{AddImplication}($\neglit{L_2}$, $L_1$, $C$)
      \If{$L_2 = \sigmaterm{\neglit {L_1}}$ for some nonidempotent $\sigma$}  \label{statement:self-impl}
      \ForAll{$i \gets 1$  to $K_\mathrm{imp}$}
         \State $L_2 \gets \sigmaterm{L_2}$
         \State \textsc{AddImplication}($\neglit L_1$, $L_2$, $C$)
      \EndFor
      \EndIf
    \EndIf
  \EndProcedure

  \kern1\jot

  \Procedure{UntrackClause}{$C$}
   %  \ForAll {$L_\mathrm{a}, L_\mathrm{c}, M$ such that $ (L_\mathrm{c}, M) \in \impmap[L_\mathrm{a}]$}
   \ForAll{$L_\mathrm{a}, L_\mathrm{c}, M$ such that $(L_\mathrm{c},M) \in \impmap[L_\mathrm{a}]$}
      \If{$C \in M$}
         \State erase $(L_\mathrm{c},M)$ from $\impmap[L_\mathrm{a}]$
      \EndIf
      % \EndFor
    \EndFor
  \EndProcedure
\end{algorithmic}
%\end{nolinenumbers}
%\end{figure}

%% TYPESETTING: hack
\vskip-1.5\jot
\vskip\belowdisplayskip

The algorithm views a clause $L \cor L'$ as two implications
$\neglit{L} \impl L'$ and $\neglit{L'} \impl L$.
%
It stores only one entry for all literals equal up to variable renaming (line
\ref{statement:alpha}). Each implication $L_\mathrm{a} \impl L_\mathrm{c}$
represented by the clause is stored only if its generalization is not present in
$\impmap$ (line~\ref{statement:more-general}). Conversely, all instances of the
implication are removed (line~\ref{statement:instances}).

Next, the algorithm
finds each implication stored in $\impmap$ that can be linked to $L_\mathrm{a} \impl L_\mathrm{c}$: Either
$L_\mathrm{c}$ becomes the new consequent (line~\ref{statement:transitivity}) or
$L_\mathrm{a}$ becomes the new antecedent (line~\ref{statement:triggered}). If
$L_\mathrm{c}$ can be decomposed into $\neqlit{u[s]}{u[t]}$, rule~3 of
Definition \ref{def:hl-fo} allows us to store $\neqlit{s}{t}$ in
$\impmap[L_\mathrm{a}]$ (line~\ref{statement:decomposition}). This is an
exception to the idea that transitive chains should use only rule~1. The
application of rule~3 does not count toward the bound $K_\mathrm{len}$.
If $L_\mathrm{a}$ is of the form $\eqlit{u[s]}{u[t]}$, then
$\impmap$ could be extended so that $\impmap[\eqlit{s}{t}] =
\impmap[L_\mathrm{a}]$, but this would substantially increase $\impmap$'s
memory footprint.

In first-order logic, different instances of the same clause can
be used along a transitive chain. For example, the clause $C =
\negpredlit{\cst{p}(x)} \cor \pospredlit{\cst{p}(\cst{f}(x))}$ induces $\cst{p}(x) \bigfimpl{M}^i \cst{p}(\cst{f}^i(x))$ for all $i$.
The algorithm discovers such self-implications (line~\ref{statement:self-impl}): For
each clause~$C$ of the form $\neglit{L} \cor \sigma(L)$, where $\sigma$ is
some nonidempotent substitution, the pairs $(\sigma^2(L), \{C\}),\allowbreak
\ldots,\allowbreak (\sigma^{K_{\mathrm{imp}} + 1}(L), \{C\})$ are added to
$\impmap[L]$, where $K_{\mathrm{imp}}$ is a parameter. 

\newcommand{\concl}{\ensuremath{\impmap^{-1}}}

\looseness=-1
To track and untrack clauses efficiently, we implement the mapping $\impmap$ as a
nonperfect discrimination tree \cite{rsv-2001-term-indexing}. Given a query
literal $L$, this indexing data structure efficiently finds all literals $L'$ such that
for some $\sigma$, $\sigmaterm{L'} = L$ and $\impmap[L'] \not= \emptyset$. We can use
it to optimize all lookups except the one on line~\ref{statement:transitivity}.
For this remaining lookup, we add an
index \concl{} that inverts $\impmap$, i.e., $\concl[L] = \{ L' \mid
\impmap[L'] = (L,M) \text{ for some } M \}$. To avoid sequentially going through
all entries in $\impmap$ when the prover deletes them, for each clause $C$
we keep track of each literal $L$ such that $C$ appears in $\impmap[L]$.
Finally, we limit the number of entries stored in $\impmap[L]$ -- by default,
up to 48 pairs in each $\impmap[L]$ are stored.

\newcommand{\unitset}{\ensuremath{\textit{Unit}}}
\begin{conf} 
\looseness=-1   
Rules \infname{HLE} and \infname{HTR} have a simple
implementation based on $\impmap$ lookups. To implement \infname{UnitHLE} and
\infname{UnitHTR}, we maintain the index \unitset, containing literals
$L_\mathrm{c}\sigma$, such that $(L_\mathrm{c}, M) \in \impmap[L_\mathrm{a}]$ for
some $M$ and $L_\mathrm{a}$ and $\sigma$ is the most general unifier of $L'$ and
$L_\mathrm{a}$, for some unit clause $\{ L' \}$. The implementation
of \infname{FLE} and \infname{FLR} also uses \unitset:
When $(L',M)$ is added to $\impmap[L]$, we
check if $(\neglit{L'},M') \in \impmap[L]$ for some $M'$. If so, $\neglit{L}$
is added to $\unitset$.
\end{conf}
\begin{rep}
   
   To implement the \infname{HLE} rule, we use $\impmap[L]$ as
   follows: Given a clause $C = L \cor L' \cor C'$, if there are two literals
   $L_1,L_2$ and a substitution $\sigma$ such that $(L_2, M) \in \impmap[L_1]$,
   $C \not\in M$,  $\sigmaterm{L_1} = L$, and $\sigmaterm{L_2} = L'$, we remove $L$ from $C$.
   Literal $L$ can also be removed if $\sigmaterm{L_1} = \neglit{L'}$ and $\sigmaterm{L_2} = \neglit{L}$. 
   Rule \infname{HTR} is implemented analogously.

% @PETAR: Used to say "UnitHTR rules rely", but there's only one. Double-check. --JB
   The \infname{UnitHTR} rule relies on maintaining the index $\unitset$, which is
   built as follows. Whenever the prover derives a unit clause $C = \{ L \}$, we
   find all entries $L_\mathrm{a}$ in $\impmap$ such that $L_\mathrm{a}$ and $L$
   are unifiable with the MGU $\sigma$. Then, we set $\unitset
   \gets \unitset \cup \{ (\sigmaterm{L_\mathrm{c}}, M \cup \{ C \} ) \mid
   (L_\mathrm{c}, M) \in \impmap[L_\mathrm{a}] \}$. Given a clause $L \cor C'$,
   we apply \infname{UnitHLE} by looking for $(L', M) \in \unitset$ such that
   $\sigmaterm{L'} = \neglit{L}$, for some substitution $\sigma$; we apply
   \infname{UnitHTR} by looking for $L'$ such that $\sigmaterm{L'} = L$.  The sets
   stored together with literals in $\unitset$ are used for building the proof
   object and to remove literals from $\unitset$ once a clause from the given
   set becomes redundant.

   The same data structure is used
   for supporting \infname{FLE} and \infname{FLR}. When $(L',M)$ is added to $\impmap[L]$, we
   check whether $(\neglit{L'},M') \in \impmap[L]$ for some $M'$. If so, $(\neglit{L}, M \cup M')$
   is added to $\unitset$.
\end{rep}


% % Using this algorithm, hidden-literal-based elimination can be implemented
% % efficiently. We implement them as simplifications, used during saturation.
% \begin{rep}
% We implement \infname{ShallowHLE} by checking if there are two literals $L,L'
% \in C$ such that for some substitution $\sigma$, and literals $L_1$ and $L_2$,
% $(L_2, M) \in \impmap[L_1]$ and $L_1\sigma = L$, $L_2\sigma = L'$, $L$ can be
% removed from $C$. When $(L',M)$ is added to $\impmap[L]$, Zipperposition checks
% if $(\neglit{L'},M) \in \impmap[L]$ for some $M$. If so, it notes that there
% are complementary literals in $\HL(\neglit{L},M)$. This information is used to
% implement \infname{FLD}. For \infname{HTR}, a check whether there are $L,L' \in
% C$ such that $(L_1, M) \in \impmap[L_0]$, where $\neglit{L_0\sigma} = L$ and
% $L_1\sigma = L'$ is performed. Rule \infname{DeepHLE} is not implemented.

% Rules \infname{UnitHLE} and \infname{UnitHTR} are implemented as well. For
% \infname{UnitHLE}, given a clause $L \cor C$ we do as follows. First we try to
% find a literal $L_0$ such that $\neglit{L_0\sigma} = L$ for some $\sigma$ and
% $(L_1,M) \in \impmap[L_0]$ such that $L_1\sigma$ is subsumed by a unit clause
% indexed by Zipperposition. If this does not succeed, we try finding a literal
% $L_0$ such that $L_0\sigma = L$ for some $\sigma$ and $(L_1,M) \in \impmap[L_0]$
% such that $\neglit{L_1}$ is subsumed by a unit clause. Rule \infname{UnitHTR} is
% implemented analogously.
% \end{rep}

In propositional logic, the conventional approach constructs the
\emph{binary implication graph} for the clause set~$N$
\cite{hjb-2011-big-simplification}, with edges $(\neglit{L}, L')$ and
$(\neglit{L'}, L)$ whenever $L \cor L' \in N.$ To avoid traversing the graph
repeatedly, solvers rely on timestamps to discover connections between
literals. This relies on syntactic literal comparisons, which is very
fast in propositional logic but not in first-order logic, because of
substitutions and congruence.

\ourpara{Predicate Elimination}
% 
To implement portfolio predicate elimination, we maintain a record for each
predicate symbol $\cst{p}$ occurring in the problem with the
following fields:\
the set of definition clauses for $\cst{p}$, the set of nondefinition clauses in which
$\cst{p}$ occurs once, and the set of clauses in which $\cst{p}$ occurs more than
once. These records are kept in a priority queue, prioritized by properties such
as the presence of definition sets and the number of estimated resolutions. If
$\cst{p}$ is the highest-priority symbol that is eligible for SPE or DPE, we
eliminate it by removing all the clauses stored in $\cst{p}$'s record from the
proof state and by adding flat resolvents to the passive set.
Eliminating a symbol might make another symbol eligible.
%In this case, the updated record is put on the processing queue.

As an optimization, predicate elimination keeps track only of symbols that appear
at most $K_\mathrm{occ}$~times in the clause set. For inprocessing, we use
signals that the prover emits whenever a clause is added to or removed from
the proof state and update the records. At the beginning of the
1st, $(K_\mathrm{iter} + 1)$st, $(2 K_\mathrm{iter} + 1)$st, $\dots{}$ iteration of the given clause procedure's
loop body, predicate elimination is systematically applied to the entire proof
state. The first application of inprocessing amounts to preprocessing. After some informal experiments,
we chose $K_\mathrm{occ} = 512$ and $K_\mathrm{iter}=10$ as default values. The analogous optimization and
limits apply for blocked clause elimination.

The most important novel aspect of our predicate elimination implementation is
recognizing the definition clauses for a symbol $\cst{p}$ in a clause set $N$, which is performed
as follows, assuming $\tupleempty{x}$ is a fixed tuple of distinct free variables:
\begin{enumerate}
   \item Let $G = \{ C \mid C = \arbpredlit{\cst{p}(\tupleempty{y})} \cor C', C \in
   N$, no variable repeats in $\tupleempty{y}$, and the variables of $C'$ are all among
   $\tupleempty{y}\}$. If $G$ is empty, report failure; otherwise, continue.

%    \smallskip
   \item Rename all clauses in $G$ so that their only variables are~$\tupleempty{x}$.

%    \smallskip
   \item\label{step:encoding} Let $\lfloor a \rfloor$ be a function that assigns
   a propositional variable to each atom $a$. This function is lifted to
   literals by assigning $\lfloor \neg a \rfloor  = \neg x$ if $\lfloor a
   \rfloor = x$, and to clauses pointwise. Furthermore,  
   let $E = \{ \lfloor C' \rfloor \mid
   \arbpredlit{\cst{p}(\tupleempty{x})} \cor C' \in G \}$. If $E$ is satisfiable,
   report failure. Otherwise, let $E'$ be an unsatisfiable core of $E$
   and $G'$ the set of corresponding first-order clauses and continue.

%    \smallskip
   \item If all resolvents in $G'_{\pospredlit{\cst{p}}} \flatres_{\!\cst{p}}
   G'_{\negpredlit{\cst{p}}}$ are tautologies, then $G'$ is a definition set
   for symbol $\cst{p}$. Otherwise, report failure.
\end{enumerate}

The invalidity of set $E$ from step \ref{step:encoding} is checked using a SAT
solver, which is already integrated in Zipperposition. As modern theorem provers
(including E and Vampire) also use SAT solvers, this definition set recognition method can easily be
implemented in those provers as well.

During experimentation, we noticed that recognizing definitions of symbols that
occur in the conjecture often harms performance. Thus, Zipperposition
recognizes definitions only for the remaining symbols.

\section{Evaluation}
\label{sec:satfol:evaluation}

% {\bf\large TODO: Evaluate \textit{real} PPE in Figure \ref{fig:preprocess} and discuss SPPE and PPE.
% References to PPE are broken now. }

\newcommand{\baseres}[0]{7897}
% \newcommand{\baseresplusfive}[0]{1563}

\newcommand{\resnum}[1]{
   \FPeval{\result}{clip(#1-\baseres)}%
   \ifnumcomp{\result}{>}{0}{$+\result$}{$\result$}%
}
\newcommand{\resnumphantom}[1]{%
   \FPeval{\result}{clip(#1-\baseres)}%
   \FPeval{\negresult}{clip(-\result)}%
   \ifnumcomp{\result}{>}{0}{\phantom{$0$}{${+}\result$}}{\phantom{$0$}{${-}\negresult$}}%
}
\newcommand{\resnumbold}[1]{
   \FPeval{\result}{clip(#1-\baseres)}%
   \FPeval{\negresult}{clip(-\result)}%
   \ifnumcomp{\result}{>}{0}{\phantom{${+}\result$}\llap{$\mathbf{\boldsymbol{+}\result}$}}{\phantom{${-}\negresult$}$\llap{\mathbf{\boldsymbol{-}\negresult}}$}%
}
\newcommand{\resnumboldphantom}[1]{%
   \FPeval{\result}{clip(#1-\baseres)}%
   \FPeval{\negresult}{clip(-\result)}%
   \ifnumcomp{\result}{>}{0}{\phantom{$0{+}\result$}\llap{$\mathbf{\phantom{0}{\boldsymbol{+}}\result}$}}{\phantom{$0{-}\negresult$}$\llap{\mathbf{\phantom{0}{\boldsymbol{-}}\negresult}}$}%
}
\newcommand{\evaluating}[0]{\textbf{?}}

\looseness=-1
We measure the impact of our elimination techniques for various values of their
parameters. As a baseline, we use Zipperposition's first-order portfolio mode,
which runs the prover in 13~configurations of
heuristic parameters in consecutive time slices. None of these configurations
use our new techniques. To evaluate a given parameter value, we fix
it across all 13~configurations and compare the results with the baseline.

\looseness=-1
The benchmark set consists of all 13\,495 CNF and FOF TPTP 7.3.0 theorems
\cite{gs-17-tptp}.
%
The experiments were carried out on StarExec servers \cite{sst-14-starexec}
equipped with Intel Xeon E5-2609 CPUs clocked at 2.40 GHz. The portfolio mode
uses a single CPU core with a CPU time limit of 180~s. The base
configuration solves \NumberOK{\baseres} problems. The values in the tables
indicate the number of problems solved minus \NumberOK{\baseres}. Thus,
positive numbers indicate gains over the baseline. The best result is shown in
bold.

\ourpara{Hidden-Literal-Based Elimination}
% 
The first experiments use all implemented HLBE rules.
To avoid overburdening Zipperposition, we can enable an option to limit the
number of tracked clauses for hidden literals. Once the limit has been reached, any
request for tracking a clause will be rejected until a tracked
clause is deleted. We can choose which kind of clauses are
tracked:\ only clauses from the active set $\mathcal{A}$,
only clauses from the passive set $\mathcal{P}$, or both.
We also vary the maximal implication chain length $K_\mathrm{len}$ and the
number of computed self-implications $K_\mathrm{imp}$.

In Zipperposition, every lookup for instances or generalizations of
$\eqlit{s}{t}$ must be done once for each orientation of the equation.
To avoid this inefficiency, and also because the implementation of hidden literals does not fully
exploit congruence, we can disable\pagebreak[2] tracking clauses with at least one
functional literal. Clauses containing functional literals can then still be
simplified.

Figures~\ref{fig:hle-clauses-neq} and \ref{fig:hle-clauses-eq}
%~\ref{fig:hle}
show the results, without and with functional literal tracking enabled,
for $K_\mathrm{len} = 2$ and $K_\mathrm{imp} = 0$.
The columns specify different limits on the number of tracked clauses, with $\infty$
denoting that no limit is imposed. The rows represent different kinds of tracked clauses.
The results suggest that tracking functional literals is \NumberOK{not} worth the effort
but that tracking predicate literals \NumberOK{is}. The best improvement is observed when
both active and passive clauses are tracked. Normally DISCOUNT-loop
provers \cite{adf-1995-discount} such as Zipperposition do not simplify
active clauses using passive clauses, but here we see that this can be effective.
%
%--Raw data shows that when up to 250 clauses in either set are
%--tracked, tracking functional literals helps solve \NumberNOK{5} problems that
%--cannot be solved by a configuration that tracks only predicate literals or the
%--base configuration. This suggests that a more optimized indexing implementation
%--would help our technique reach its full potential.
Figure~\ref{fig:km-kimp} shows the impact of varying $K_\mathrm{len}$ and
$K_\mathrm{imp}$, when 500 clauses from the entire proof state are tracked.
These results suggest that computing long implication chains \NumberOK{is counterproductive.}
% Furthermore, raw data reveals that there is
% no gain in this case: not a single problem that configuration with $K_\mathrm{len}=2$ and
% $K_\mathrm{imp}=0$ cannot solve is solved when $K_\mathrm{imp}K_\mathrm{len}$ is set to 8 and
% $K_\mathrm{imp}$ to 0.

\begin{figure}[t]
   \centering
   \begin{minipage}{.48\textwidth}
     \begin{center}
       \def\arraystretch{1.1}%
       \relax{\begin{tabular}[t]{l@{\hskip 1em}c@{\hskip 1em}c@{\hskip1em}c@{\hskip 1em}c}
         & \multicolumn{4}{c}{Tracked clauses} \\
         & $250$        & $500$         & $1000$       &$\infty$ \\ \midrule 
\strut Active       & \resnum{7883}  & \resnum{7881}   & \resnum{7889}  & \resnum{7885}    \\
\strut Passive      & \resnumphantom{7904}  & \resnum{7907}   & \resnum{7902}  & \resnum{7862}    \\
\strut Both         & \resnumbold{7909}  & \resnum{7907}   & \resnum{7904}  & \resnum{7852} \\     
\end{tabular}}
\caption{Impact of the number and kinds of tracked clauses on HLBE performance, when only predicate literals are tracked}
\label{fig:hle-clauses-neq}
     \end{center}
   \end{minipage}
   \hfill
   \begin{minipage}{.45\textwidth}
     \begin{center}
       \def\arraystretch{1.1}%
       \relax{\begin{tabular}[t]{l@{\hskip 1em}c@{\hskip 1em}c@{\hskip1em}c@{\hskip 1em}c}
         & \multicolumn{4}{c}{Tracked clauses} \\
         & $250$                   & $500$                 & $1000$                    & $\infty$ \\ \midrule 
\strut Active       & \resnum{7887}            & \resnum{7883}         & \resnumphantom{7889}      & \resnum{7879}    \\
\strut Passive      & \resnumphantom{7892}     & \resnumphantom{7892}  & \resnum{7883}             & \resnum{7826}    \\
\strut Both         & \resnumboldphantom{7899} & \resnumphantom{7896}  & \resnumphantom{7889}      & \resnum{7818} \\ 
\end{tabular}}
\caption{Impact of the number and kinds of tracked clauses on HLBE performance, when all literals are tracked}
\label{fig:hle-clauses-eq}
     \end{center}
   \end{minipage}
 \end{figure}


 

\begin{figure}[t]
\small
\centering
\def\arraystretch{1.1}%
\begin{tabular}[t]{l@{\hskip 2em}c@{\hskip 1.5em}c@{\hskip1.5em}c@{\hskip 1.5em}c} 
                             & \multicolumn{4}{c}{Chain length $K_\mathrm{len}$} \\
                             & $1$                   & $2$                 & $4$                   & $8$ \\ \midrule 
   $K_\mathrm{imp}=0$        & \resnum{7906}         & \resnum{7907}       & \resnum{7904}         & \resnum{7902}    \\
   $K_\mathrm{imp}=1$        & \resnum{7902}         & \resnumbold{7908}       & \resnum{7904}         & \resnum{7901}    \\
   $K_\mathrm{imp}=2$        & \resnum{7903}         & \resnumbold{7908}       & \resnum{7905}         & \resnum{7905}    \\
\end{tabular}
\caption{Impact of the parameters $K_\mathrm{len}$ and $K_\mathrm{imp}$ on HLBE performance}
\label{fig:km-kimp}
\end{figure}

\begin{figure}[t!]
   \small
   \centering
   \def\arraystretch{1.1}%
   \begin{tabular}[t]{l@{\hskip 1.5em}c@{\hskip 1.5em}c@{\hskip 1em}c@{\hskip 1em}c@{\hskip 1em}c@{\hskip 1em}c}
                           &               & \multicolumn{5}{c}{Relaxed with $K_\mathrm{tol}$} \\
                           & K\&K          & $0$             & $25$           & $50$           & $100$    & $200$    \\ \midrule 
   \infname{SPE} preprocessing  & \resnum{7967} & \resnum{8014}   & \resnum{8051}  & \resnum{8057}  & \resnum{8051}      & \resnum{8055} \\
   \infname{PPE} preprocessing  & \resnum{7968} & \resnum{8021}   & \resnum{8057}  & \resnum{8061}  & \resnumbold{8062}      & \resnum{8059} \\
   \end{tabular}
   \caption{Impact of the choice of criterion on predicate elimination performance}
   \label{fig:criterion}
\end{figure}

\begin{figure}[t]
   \small
   \centering
   \def\arraystretch{1.1}%
   \begin{tabular}[t]{l@{\hskip 1em}c@{\hskip 1.3em}c@{\hskip 1em}c@{\hskip 1.3em}c@{\hskip 1em}c@{\hskip 1.3em}c}
                         &               &               &                &               &                    & \smash{HLBE} \\[-1pt] %% TYPESETTING
                         &               &               & \smash{SPE}    &               & \smash{PPE}        & \smash{+PPE} \\[-1pt] %% TYPESETTING
                         & BCE           & SPE           & +BCE           & PPE           & +BCE               & +BCE           \\ \midrule 
   \strut Preprocessing  & \resnum{7927} & \resnum{8051} & \resnum{8056}  & \resnum{8057} & \resnumbold{8063}  & \resnum{8059} \\
   \strut Inprocessing   & \resnum{7849} & \resnum{8037} & \resnum{8024}  & \resnum{8043} & \resnum{8028}      & \resnum{8024}     \\
   \end{tabular}
   \caption{Performance of predicate and blocked clause elimination}
   \label{fig:preprocess}
\end{figure}


\renewcommand{\baseres}{856}

\begin{figure}[t]
   \small
   \centering
   \def\arraystretch{1.1}%
   \begin{tabular}[t]{l@{\hskip 1em}c@{\hskip 1.3em}c@{\hskip 1em}c@{\hskip 1.3em}c@{\hskip 1em}c@{\hskip 1em}c} \\
                         &              &              &                   &              &              & \smash{HLBE}   \\[-1pt] 
                         &              &              & \smash{SPE}       &              & \smash{PPE}  & \smash{+PPE}   \\[-1pt] 
                         & BCE          & SPE          & +BCE              & PPE          & +BCE          & \smash{+BCE}    \\ \midrule 
   \strut Preprocessing  & \resnum{885} & \resnum{902} & \resnumbold{916}  & \resnum{903} & \resnum{915} & \resnum{911}  \\
   \end{tabular}
   \caption{Performance of predicate and blocked clause elimination for establishing satisfiability}
   \label{fig:bce-sat}
\end{figure}

\ourpara{Predicate and Blocked Clause Elimination}
%
% \textit{Evaluation results discussion paragraph---here effects of definitions can be discussed}
% \textit{Do not forget to mention SPE was already implemented and }
For defined predicate elimination, the number of resolvents grows
exponentially with the number of occurrences of $\cst{p}$. To avoid this expensive
computation, we limit the applicability of PPE to proof states for which $\cst{p}$
is singular. According to our informal experiments, full PPE,
without this restriction, generally performs less well.

\begin{qle}\color{red} (TODO: Add QLE)\color{black}\end{qle}

Predicate elimination can be done using Khasidashvili and Korovin's
criterion (K\&K) or using our relaxed criterion with different values of
$K_\mathrm{tol}$. Figure~\ref{fig:criterion} shows the results
for SPE and PPE used as preprocessors.
Our numbers corroborate Khasidashvili and Korovin's findings:
SPE with K\&K proves \NumberOK{70} more problems than the base, a
\NumberOK{0.9\%} increase, comparable to the 1.8\% they observe when
they combine SPE with additional preprocessing.
Remarkably, the number of additional proved problems more than
\NumberOK{doubles} when we use our criterion with $K_\mathrm{tol} > 0$, for both SPE and PPE.

\looseness=-1
Although this is not evident in Figure~\ref{fig:criterion}, varying
$K_\mathrm{tol}$ substantially changes the set of problems solved. For example,
when $K_\mathrm{tol}=0$, SPE proves \NumberOK{60} theorems not proved using
$K_\mathrm{tol}=50$. The effect weakens as $K_\mathrm{tol}$ grows. When
$K_\mathrm{tol}=100$, SPE proves only \NumberOK{13} problems not found when
$K_\mathrm{tol}=200$. Similarly, the set of problems proved by SPE and PPE
differs: When $K_\mathrm{tol}=25$, \NumberOK{14} problems are proved by PPE but
missed by SPE. Recognizing definition sets is useful:
PPE \NumberOK{outperforms} SPE regardless of the criterion.

% \looseness=-1 Having implemented those techniques, we are in position to answer
% two interesting questions: {How helpful are definition clauses in defined
% predicate elimination (DPE)?} and {What are the effects of performing blocked
% clause elimination (BCE) and DPE until fixpoint (BD)?}. The second question was
% also of interest to Kiesl et al.\ \cite{ksstb-2017-blockedfol}, but was left
% unanswered as they did not implement predicate elimination.

\looseness=-1
Performing BCE and variable elimination until fixpoint increases the performance
of SAT solvers~\cite{jbh-10-BCE}. We can check whether the same holds for superposition provers.
In this experiment, we use the relaxed criterion with
$K_\mathrm{tol}=25$ and HLBE which tracks up
to 500 clauses from any clause set, $K_\mathrm{len}=2$, and
$K_{\mathrm{imp}}=0$. We use each technique as preprocessing and inprocessing.

The results are summarized in Figure~\ref{fig:preprocess}, where
the +~sign denotes the combination of techniques.
We confirm the results obtained by Kiesl et al.\ about the performance of BCE
as preprocessing:
It helps prove \NumberOK{30} more problems from our benchmark set, increasing the
success rate by roughly \NumberOK{0.4\%}. The same percentage increase was obtained by Kiesl et al.
%
Using BCE as inprocessing, however, hurts performance, presumably because of
its incompatibility with the redundancy criterion.

\looseness=-1%
For preprocessing, the combinations SPE+BCE and PPE+BCE performed roughly \NumberOK{on a
par} with SPE and PPE, respectively. This stands in contrast to the situation
with SAT solvers, where such a combination usually helps. It is also worth noting
that the inprocessing techniques never outperform their preprocessing
counterparts.
%
The last column shows that combining HLBE with other elimination techniques
\NumberOK{overburdens} the prover.


\ourpara{Satisfiability by Blocked Clause Elimination}
%
\looseness=-1%
Kiesl et al.\ found that blocked clause elimination is especially effective on
satisfiable problems. To corroborate their results and ascertain
whether a combination of predicate elimination and blocked clause elimination
increases the success rate, we evaluate BCE on all 2273
satisfiable TPTP FOF and CNF problems.
The hardware and CPU time limits are the same as in the experiments above.
Figure~\ref{fig:bce-sat} presents the results.

\looseness=-1
The baseline establishes the satisfiability of \baseres~problems. We consider
only preprocessing techniques, since BCE compromises refutational
completeness---a saturation does not guarantee that the original problem is
satisfiable. We note that recognizing definition sets makes almost no difference on
satisfiable problems. The sets of problems solved by BCE and PPE
differ---\NumberOK{30} problems are solved by BCE and not by PPE.
% Kiesl sees around 2.5%, we see 3.5% with BCE

\section{Discussion and Related Work}
\label{sec:satfol:discussion-and-related-work}

We briefly surveyed related work in Sect.~\ref{sec:satfol:introduction}. In this
section, we give a more detailed overview and further discuss connections with
related work.

The research presented in this \paper{} is two-pronged. For SAT elimination
techniques already generalized to preprocess first-order problems, we looked for
ways to interleave them with the given clause procedure of a superposition
prover, as inprocessing. For techniques that had not yet been ported to
first-order logic, we looked for generalizations that allow both preprocessing and
inprocessing.

Hidden tautology elimination was first described
by Heule et al.\ \cite{hjb-2010-cl-elim}. A better implementation that also
supports hidden literal elimination was later described by the same group of
authors \cite{hjb-2011-big-simplification}. We generalized the underlying
theoretical concepts to first-order logic, and provided an efficient way to deal
with the infinite number of hidden literals that arise  with this
generalization. More efficient graph-based techniques are yet to be explored.

Variable elimination, based on Davis--Putnam resolution \cite{dp-60-dp}, has been studied in
the context of both propositional logic \cite{sp-04-niver,cs-00-zres} and QBF
\cite{ab-2004-re}. It was generalized to first-order logic (as a
preprocessor) by Khasidashvili and Korovin \cite{kk-2016-pe-fol}, yielding a technique called
predicate elimination. An improvement of variable elimination,
that uses formula definition information, has been popularized as a preprocessing and
inprocessing technique for CDCL solvers by E{\'{e}}n and Biere
\cite{eb-2005-satpreprocess}. We generalized this improvement to first-order
logic and combined it with Khasidashvili and Korovin's approach. With tolerable restrictions,
this extension can be used as an inprocessing technique. In SAT and QBF, it was observed that
allowing variable elimination to slightly increase the clause set size
improves performance \cite{bls-11-bloqqer}. We implemented a similar approach,
achieving double the number of additional proofs found compared to more
restrictive approaches.

Blocked clause elimination is used in both SAT~\cite{jbh-10-BCE} and QBF
solvers \cite{bls-11-bloqqer}. Its generalization to first-order logic
\cite{ksstb-2017-blockedfol} has showed positive effects when used as a
preprocessor. We showed that blocked clauses cannot be removed during
saturation, but that they can be effectively used to show satisfiability of the
clause set. A combination of blocked clause elimination and
variable elimination performs well in propositional logic \cite{jbh-10-BCE}, but we observed no comparable
improvement when their generalizations are combined.

Our general approach is one of many ways to combine ideas from SAT solving and
first-order proving. Other noteworthy architectures that either incorporate a
SAT solver or that generalize the CDCL calculus include DPLL($T$) with
quantifier instantiation
\cite{de-moura-bjoerner-2007,barbosa-et-al-2017,reynolds-et-al-2018},
DPLL($\mupGamma+T$) \cite{bonacina-et-al-2009},
labeled splitting \cite{fietzke-weidenbach-2009},
AVATAR \cite{av-2014-avatar},
MCSAT \cite{de-moura-jovanovic-2013},
CDSAT \cite{bonacina-et-al-2017}, and
SGGS~\cite{bonacina-plaisted-2014}.

\section{Conclusion}
\label{sec:satfol:conclusion}

We adapted several preprocessing and inprocessing elimination techniques implemented in
modern SAT solvers so that they work in a superposition prover. This involved lifting
the techniques to first-order logic with equality but also tailoring them to
work in tandem with superposition and its redundancy criterion.
Although SAT solvers and superposition provers embody radically different
philosophies, we found that the lifted SAT techniques provide valuable optimizations.

\pagebreak[2]
We see several avenues for future work. First, the implementation of hidden
literals could be extended to exploit equality congruence. Second, although
blocked clause elimination is generally incomplete as an inprocessing technique,
we hope to achieve
refutational completeness for a substantial fragment of it. Third, predicate and
blocked clause elimination, which thrive on the absence of clauses from the
proof state, could be enhanced by tagging and ignoring generated clauses that
have not yet been used to subsume or simplify untagged clauses. Fourth,
predicate and blocked clause elimination could be extended to work with
functional literals. Fifth, more SAT techniques could be adapted, including
bounded variable addition~\cite{mhb-12-reencoding} and blocked clause
addition~\cite{ok-99-er}. Sixth, the techniques we covered could be adapted to
work with other first-order calculi, or generalized
further to work with higher-order calculi such as combinatory superposition
\cite{br-20-full-sup-w-combs} and \osup{}.
