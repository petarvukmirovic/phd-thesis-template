\chapter{Conclusion}
\setheader{Conclusion}
\label{ch:conclusion}
 
As we bring this thesis to an end, I would like to use these last pages to
reflect not only on the work I did in the last four years, but also on the
many bumps on the road that I did not get to describe in the preceding chapters.
When it comes to reflections, the  performance art piece Rhythm 10, performed by
Marina Abramovi\'c,  one of the greatest Yugoslav artists, comes to my mind. The
themes that it explores such as taking risks and inevitability of making
mistakes were the root of fears and doubts that I was slowly overcoming over the
last four years. The photograph on the cover of this thesis was taken when it
was first performed, in Edinburgh, in 1973. The instructions for the performance read:

\begin{quote}
    \underline{Preparation} \\[1\jot]
    I place a sheet of white paper on the floor.\\
    I lay 20 knives of different sizes and shapes on the floor.\\
    I place 2 tape recorders with microphones on the floor.
    
    \underline{Performance} \\[1\jot]
    I turn on the first tape recorder.\\
    I take the first knife and stab in between the fingers of my left hand as
    fast as possible.\\
    Every time I cut myself, I change to a different knife. \\
    When I've used all of the knives (all the rhythms), I rewind the tape
    recorder. \\ 
    I listen to the recording of the first part of the performance. \\ I
    concentrate. \\
    I repeat the first part of the performance. \\
    I take the knives in the same order, follow to the same order, follow to the
    same rhythm and cut myself in the same places. \\
    In this performance, the mistakes of time past and time present are
    synchronized.\\
    I rewind the second tape recorder and listen to the double rhythm of the
    knives.\\
    I leave.
\end{quote}

The work that I have done for my thesis
was cyclic: It consists of three phases (three stops as we described them in
Chapter \ref{ch:intro}), each of which has the same parts: theory (calculus and
algorithms), engineering (implementation) and optimization (heuristics). While
the calculi were mostly developed by Alexander Bentkamp
\cite{bbcw-21-lfho,bbtvw-21-sup-lam,bbtv-21-full-ho-sup}, the task of developing
algorithms for indexing or unification, as well as the tasks of implementing and
optimizing the implementation were mainly mine.

Structuring the project cyclically turned out to be a great idea of my
supervisor. When I first started doing the research which will later form the
basis of Chapter \ref{ch:ehoh}, I was overwhelmed by the scope of the project
and felt uncertain if E could ever fully support $\lambda$-free higher-order
logic. Many of the extensions described in the  later chapters were even larger
in scope. However, as each extension relied on the previous one, I quickly
developed a feeling of where the possible pitfalls are and how to avoid them.
This gave me an invaluable source of encouragement, without which I could hardly
arrive at the end of the project.

The work in Chapter~\ref{ch:ehoh} completed the first cycle. Soon after the
original paper introducing Ehoh \cite{vbss-19-ehoh1} was published, Ehoh found
its use as the backend of Sledgehammer and Satallax, showing that even when
limited to a fragment of higher-order logic, efficient higher-order reasoning is
in demand.

\looseness=-1
The goal of the next cycle was to support $\lambda$-abstraction. When we first
implemented \lsup{}, the calculus that achieves this goal, we quickly realized that
one of its main flaws was that it relies on enumerating full unifiers rather
than preunifiers, like some older resolution-based higher-order calculi do. This
is why we focused on developing a full unification procedure that removes the
redundancy present in other procedures. It also implements many advancements
and optimizations described in the unification literature after the introduction
of the most influential full unification procedure, Jensen-Pietrzykowski's
procedure in 1970s. We also made sure that our procedure can easily be customized to
trade bits of its completeness for substantially improved performance. This
procedure, described in Chapter~\ref{ch:unif}, transformed the \lsup{} calculus
into a competitive higher-order calculus.

Even though \lsup{} became competitive, its implementation in Zipperposition
lagged behind the competition. To investigate why this is the case,
we manually analyzed hundreds of benchmarks which the competition proves, but
on which Zipperposition fails. This analysis forms the basis of work that is
described in Chapters \ref{ch:bools} and \ref{ch:ho-techniques}. The main
conclusion was that the competition, most notably tableaux-based Satallax,
reasons better with formulas. Tableaux inferences are more intuitive than the
ones that superposition or resolution provers perform and are more in line with
how a mathematician structures a proof. Fitting these kind of
inferences into the superposition context was challenging, but it proved very
successful. After they were implemented in Zipperposition, it took its first
victory at higher-order division of CASC.

Our extension of \lsup{} was guided by performance, rather than completeness
with respect to full higher-order logic. After the first victory, we were left
wondering what were the kind of problems that our implementation cannot
solve, and started looking for complete full higher-order calculus. At the end,
we designed \osup{} which gave us the precise answer in the form of problems that
cannot be solved and the rules which are necessary to solve them. 

While preparing for the following year's CASC competition, we found problems
that occur in practice for which the rules of \osup{} are necessary. However,
these problems occur in less than one percent of the whole TPTP library.
Furthermore, some of \osup{}'s rule are so explosive that they are disabled in
most of CASC portfolio configurations.

This lead us to take a radically different approach when extending Ehoh to
\ehohii{}. We envisioned \ehohii{} as a prover that excels on problems coming
from proof assistants, in which hard, hand-crafted mathematical puzzles rarely occur.
Thus, we conjectured that extending \lfsup{} with the most rudimentary features
of $\lambda$ superposition such as full higher-order unification and
$\beta$-reduction-aware term orders will help us prove most of higher-order
problems without the explosion of complete approaches.

While this proved mostly true, we quickly realized that \ehohii{} should
assimilate most of incomplete Boolean reasoning techniques described in Chapters
\ref{ch:bools} and \ref{ch:ho-techniques}. All of them were straightforward to
implement except for dynamic clausification. It is possible that support for
this technique does not require profound changes to E(hoh)'s formula treatment,
but due to the lack of time we did not explore this alley.

This highly pragmatic approach proved successful not only on proof assistant
benchmarks: \ehohii{} also excels on TPTP benchmarks, trailing slightly behind
Zipperposition. By manually expecting the TPTP benchmarks that are out of reach
for \ehohii{}, but within the reach of Zipperposition, we realized that lack of
dynamic clausification might be the weight necessary to tip the scale in the
favor of \ehohii{} on TPTP benchmarks.

This extension of Ehoh to \ehohii{} finished the third cycle. Inspired by our
approach of extending techniques designed for weaker logics to work in the
context of richer logics, we decided to look for ways in which superposition can
assimilate the most successful techniques of SAT solving. Extension of hidden
literals was straightforward, but finding the right way to tame their infinite
nature in the first-order case, as well as the right way to integrate equality
in their definition was challenging. Predicate elimination posed challenges in
terms of finding the exact conditions in which it can be integrated with the
saturation loop. We first observed that blocked clause elimination destroys the
completeness of superposition calculus when we noticed that Zipperposition does
not prove some problems when the technique is enabled. After sifting through tens of
benchmarks and carefully examining the debugging information we realized that
this was not due to a bug in the implementation but due to incompatibility of
blocked clause elimination with redundancy criterion. In the end, we were left
somewhat disappointed to learn that SAT techniques do not scale good enough to be used
as superposition simplification techniques. However, we learned that they are
very successful as preprocessing techniques.

As it is customary, we will conclude the thesis with some remarks about the future work. \ehohii{} has been brought to the shape
in which further experimentation with higher-order superposition is possible.
From the experience gained in Chapters \ref{ch:bools} and
\ref{ch:ho-techniques}, we can point out dynamic clausification as the main
feature that is not yet implemented. We plan on implementing it in future.

In Chapter \ref{ch:ho-techniques} we only scratched the surface of finding the
appropriate heuristics. Now that \ehohii{} implements more advanced higher-order
reasoning it would be interesting to verify that our heuristics are agnostic of
the version of implemented higher-order superposition calculus. 

Some of the SAT-based techniques described in Chapter~\ref{ch:satfol} are
implemented in E as well. However, this implementation is still in its early
phases as it is not properly tested and optimized. Verifying the techniques are
prover-agnostic would increase the confidence in them. We also started the work of extending
those techniques to full higher-order logic.
