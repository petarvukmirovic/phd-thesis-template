\chapter{Preliminaries}
\setheader{Preliminaries}
\label{ch:pre}

\begin{abstract}
    In this chapter we lay out the basic prerequisites for the remaining
    chapters. We begin by describing the three logics that we work with in this
    thesis: propositional logic, monomorphic first-order logic and simply typed
    higher-order logic. Then, we explain the clausal structure which is the
    backbone of many calculi for automated provers. We finish with the description of the
    superposition calculus.
\end{abstract}
      
\newpage

Our work mostly concerns retrofitting first-order provers to support
higher-order concepts. But part of our work also concerns integrating
successful approaches for propositional logic in first-order
provers. We begin by defining all three logics, in the increasing
order of expressivity.

\section{Propositional Logic}

Atomic formulas of propositional logic are propositional variables
$\cst{p}, \cst{q}, \ldots$ and constants $\top$ and $\bot$. More complex
formulas are built inductively using logical connectives $\inot, \iand, \ior,
\iimplies, \allowbreak \iequiv$: if $\phi$ and $\psi$ are formulas, then $\inot \phi, \phi \iand
\psi, \allowbreak \phi \ior \psi, \phi \iimplies \psi, \phi \iequiv \psi$ are formulas as well.

To interpret the formulas, propositional variables are assigned 0 (false) or 1
(true), constants $\top$ and $\bot$ are assigned 1 and 0 respectively and the
formula is interpreted using the rules for each connective
\cite[Sect.~1.4]{hr-00-logic-in-cs}. As there are finitely many propositional
variables in a formula, trying all (finitely many) possible variable assignments
describes an algorithm to decide satisfiability (existence of satisfiable
assignment for a formula) or validity (if all assignments are satisfy the formula).

However, this simple approach is prohibitively expensive and modern tools that
decide propositional satisfiability problem (SAT solvers) use more advanced
approaches such as CDCL calculus \cite{mss-96-cdcl}. Modern SAT solvers also
heavily preprocess the problem and continue simplifying it during proving
process.

\section{First-Order Logic}

First-order logic increases the expressivity by allowing quantification over
objects and has more complicated formula structure. There are many flavors of
first-order logic, but in this thesis we consider monomorphic first-order logic
with equality.

We distinguish a set of base types $T$ which is required to have the Boolean
type $o$, and a set of symbols $\Sigma$. To each symbol $\cst{f} \in \Sigma$ a
tuple $(\tau_1, \ldots, \tau_{n}, \tau), n \geq 0$ of types is assigned, written
$\cst{f} : (\tau_1, \ldots, \tau_{n}) \rightarrow \tau$. We say that $(\tau_1,
\ldots, \tau_{n})$ are argument types, $\tau$ is the return type, and that $n$
is the arity of the symbol $\cst{f}$. If return type of $\cst{f}$ is $o$ we call
$\cst{f}$ a predicate symbol, otherwise we call it a function symbol. Argument types may not be Boolean.

Terms are the basic building blocks of first-order logic. Variables
$x,y,\ldots$, assigned types $\tau \in T$, are terms. If $t_1,\ldots,t_n$ are
terms of types $\tau_1, \ldots, \tau_n$, respectively, and $\cst{f} : (\tau_1,
\ldots, \tau_{n}) \rightarrow \tau$, then $\cst{f}(t_1, \ldots, t_n)$ is a term
of type $\tau$. If $n=0$, we drop parentheses and write $\cst{f}$. We also
abbreviate $\cst{f}(t_1, \ldots, t_n)$ to $\cst{f}(\tuplen{t})$. Using similar notation,
we abbreviate a tuple of terms $(t_1, \ldots, t_n)$ as $(\tuplen{t})$ or simply $\tuplen{t}$.

Terms are used to build atoms. Atom is either a term $t$ of type $o$ or an
equation $s \eq t$ where terms $t$ and and $s$ are of the same type. Atoms are
combined using logical connectives to build formulas just like in propositional
logic. Additionally, first-order formulas are built using quantifiers: if $\phi$
is a formula and $x$ is a variable then $\iforall x.\, \phi$, as well as
$\iexists x.\, \phi$ are formulas. The first formula requires that $\phi$ holds
for any value of $x$, while the second one requires that there is some $x$ for
which $\phi$ holds. As soon as there is a single functional symbol with arity
greater than 0, there are infinitely many terms that can be substituted for a
free variable. Furthermore, in first-order logic to determine the truth value of
the formula, it does not suffice to assign values to variables. It is also
necessary to interpret symbols. Therefore, it is obvious that the propositional
technique for deciding satisfiability does not work in the first-order case.

A position in a term is a tuple of natural numbers, with $\varepsilon$ denoting
the empty tuple. Subterms and positions are inductively defined as follows.
Term $t$ is a subterm of itself at position $\varepsilon$. If $s$ is a subterm
of $t_i$ at position $p$, then $s$ is a subterm of $\cst{f}(\tuplen{t})$ at
position $i.p$. A context is a term with zero or more subterms replaced by a
hole $\square$. We write $C[\overline{u}_n]$ for the term resulting from filling
in the holes of a context $C$ with the terms $\overline{u}_n$, left to
right.

Substitutions $\sigma, \varrho, \ldots$ are total mappings from variables to
terms of the same type. Substitutions map only finitely many variables to terms
other than the variable itself. This is denoted as $\{ x_1 \mapsto t_1, \ldots,
x_n \mapsto t_n \}$ where $x_i$ are variables that are not mapped to itself.
Applying a substitution $\sigma$ to a term $t$, denoted $\sigma(t)$ results in
replacing all mapped variables by the corresponding terms.
The composition $\varrho\sigma$ of substitutions is defined by
$\left(\varrho\sigma\right)t=\varrho\left(\sigma t\right)$.

\section{Higher-Order Logic}

In this thesis we use classic simply typed monomorphic higher-order logic with
the choice operator (and some variations of this logic). Assuming a set of
base types $T$ and a set of symbols $\Sigma$, let us
define terms and types. Types are either base types $\tau \in T$, or function
types $\tau_1 \rightarrow \tau_2$ where both $\tau_1$ and $\tau_2$ are types.
Each symbol $\cst{f} \in \Sigma$ is assigned a type.

Terms are defined as free variables $F, X, \ldots$, bound variables $x, y, z,
\dotsc$, or symbols $\cst{f}, \cst{g},\allowbreak \cst{a},\allowbreak \cst{b}
\dotsc$. Furthermore, if $s$ and $t$ are terms of type $\tau_1 \rightarrow
\tau_2$, and $\tau_1$, respectively, then $s \, t$ is a term of type $\tau_2$.
Lastly, if $x$ is a bound variable of type $\tau_1$ and $s$ is a term of type
$\tau_2$, then $\lambda$-abstractions $\lamx{s}$ is a term of type $\tau_1
\rightarrow \tau_2$. The syntactic distinction between free and bound variables
gives rise to \emph{loose bound variables} (e.g., $y$ in $\lamx{y \, \cst{a}}$)
\cite{tn-93-patterns}.

We assume the standard notions of $\alpha$, $\beta$ and $\eta$ conversions and
write $s \equi t$ if terms $s$ and $t$ are equal modulo $\alpha\beta\eta$
converison. We let $s \, \overline{t}_n$ stand for $s \, t_1 \, \ldots \, t_n$
and $\lam{\overline{x}_n}{s}$ for $\lambda x_1. \ldots \lambda x_n. \> s$. Every
$\beta$-reduced term can be written as $\lam{\tuple{x}{m}}{a \, \tuplen{t}}$,
where $a$ is not an application; we call $a$ the \emph{head} of the term. By
convention, $a$ and $b$ denote heads. If $a$ is a free variable, we call the term
\emph{flex}; otherwise, the term is \emph{rigid}.

Deviating from the standard notion of higher-order subterm, we define subterms
on $\beta$-reduced terms as follows: a term $t$ is a subterm of $t$ at position
$\varepsilon$. If $s$ is a subterm of $u_i$ at position $p$, then $s$ is a
subterm of $a\;\overline{u}_n$ at position $i.p$. If $s$ is a subterm of $t$ at
position $p$, then $s$ is a subterm of $\lambda x.\, t$ at position $1.p$. Our
definition of subterm gracefully generalizes the corresponding first-order
notion: $\cst{a}$ is a subterm of $\cst{f} \, \cst{a} \, \cst{b}$ at position 1,
but $\cst{f}$ and $\cst{f} \, \cst{a}$ are not subterms of $\cst{f} \, \cst{a}
\, \cst{b}$. 

Higher-order substitutions ($\sigma,\varrho,\ldots$) are functions from free and bound
variables to terms. A variable $F$ is mapped by $\sigma$ if $ \sigma F \not\equi
F$. Each substitution maps only finitely many variables, and it is denoted as in
first-order case. Application of  $\sigma$ to term $t$ is denoted $\sigma(t)$;
this application $\alpha$-renames $t$ to avoid variable capture. For example,
$\{X \mapsto x\}(\lamx{X \, a})$ results in $\lam{y}{x \, a}$.  Given a substitution
$\varrho$, which maps $F$ to $s$, we write $\varrho\setminus\{F \mapsto s\}$ to
denote a substitution that does not map $F$ and otherwise coincides with
$\varrho$. Given substitutions $\varrho$ and $\sigma$, which map disjoint sets
of variables, we write $\varrho \cup \sigma$ to denote $\varrho\sigma$.

Throughout this thesis, we consider completeness of higher-order calculi only
with respect to Henkin semantics \cite{bm-14-automation-ho}. Note that no
complete calculus exists for higher-order calculi with standard (full)
semantics.
\section{Clausal Forms}
\section{Superposition}
\subsection{Term Order and Selection}
\subsection{Unification}
\subsection{Inference Rules}
\subsection{The Redundancy Criterion}
\subsection{The Saturation Procedure}
